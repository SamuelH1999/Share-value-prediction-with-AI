{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19628bf5",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c450942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e4b287",
   "metadata": {},
   "source": [
    "# function to download stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6782e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(stock_symbols, start_date, end_date, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write heading of the columns\n",
    "        f.write('Date,Open,High,Low,Close,Volume\\n')\n",
    "        # load share data for the time period needed\n",
    "        stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "        stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]  # Choose the right columns\n",
    "        stock_data.to_csv(f, header=False)  # Write the data to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a982667",
   "metadata": {},
   "source": [
    "# Define the shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b93e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = ['ALV.DE', 'DBK.DE', 'VOW3.DE', 'BMW.DE', 'ADS.DE', 'BEI.DE', 'DTE.SG', 'SAP.DE', '1COV.DE', 'BAS.DE', 'EOAN.DE', 'RWE.DE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04709944",
   "metadata": {},
   "source": [
    "# Read start and end for the sequence, which will be predicted from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8534b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Startdatum: 2024-04-01, Enddatum: 2024-04-30\n"
     ]
    }
   ],
   "source": [
    "excel_file_path = 'settings/actualMonth_startEnd.xlsx'\n",
    "\n",
    "# Path to file, in which the index is stored\n",
    "index_file_path = 'settings/actualMonthIndex.txt'\n",
    "\n",
    "# Read the current index from the index file\n",
    "try:\n",
    "    with open(index_file_path, 'r') as index_file:\n",
    "        current_row_index = int(index_file.read().strip())\n",
    "except FileNotFoundError:\n",
    "    current_row_index = 0\n",
    "print(current_row_index)\n",
    "# read excel file\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Check, if the index is out of bounds\n",
    "if current_row_index >= len(df):\n",
    "    print(\"Es gibt keine weiteren Zeilen in der Excel-Tabelle.\")\n",
    "else:\n",
    "    # extract the data from the current row\n",
    "    start_date = df.loc[current_row_index, 'start_date']\n",
    "    end_date = df.loc[current_row_index, 'end_date']\n",
    "\n",
    "    # Output of the current data\n",
    "    print(f'Startdatum: {start_date}, Enddatum: {end_date}')\n",
    "\n",
    "    # Updating the index in the index file for the next call\n",
    "    with open(index_file_path, 'w') as index_file:\n",
    "        index_file.write(str(current_row_index + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a78c31",
   "metadata": {},
   "source": [
    "# Read close values at the begin of the time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da22874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-27 00:00:00\n",
      "2024-03-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Definition of the time period\n",
    "# convert in to datetime objekt to substract days for the last day before this period\n",
    "start_date_obj = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_obj = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "# Substract 5 days for the new start_date and 1 day for the new end_date\n",
    "# In the next block the last date will be extracted \n",
    "new_start_date = start_date_obj - timedelta(days=5)\n",
    "new_end_date = start_date_obj - timedelta(days=1)\n",
    "\n",
    "print(new_start_date)\n",
    "print(new_end_date)\n",
    "\n",
    "# Load and store the data for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_begin{symbol}.csv'\n",
    "    download_stock_data(symbol, new_start_date, new_end_date, output_file)\n",
    "\n",
    "    # Search and delete empty rows in the CSV file\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the cleaned data\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea464ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel\\AppData\\Local\\Temp\\ipykernel_17300\\18960333.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_data_begin = combined_data_begin.append(risk_free_data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Symbol  Close_Value\n",
      "0      ALV.DE   277.799988\n",
      "1      DBK.DE    14.582000\n",
      "2     VOW3.DE   122.839996\n",
      "3      BMW.DE   106.959999\n",
      "4      ADS.DE   207.000000\n",
      "5      BEI.DE   134.949997\n",
      "6      DTE.SG    22.434999\n",
      "7      SAP.DE   180.460007\n",
      "8     1COV.DE    50.680000\n",
      "9      BAS.DE    52.930000\n",
      "10    EOAN.DE    12.885000\n",
      "11     RWE.DE    31.459999\n",
      "12  Risk_Free   100.000000\n"
     ]
    }
   ],
   "source": [
    "# create data frame for the collected data \n",
    "combined_data_begin = pd.DataFrame(columns=['Symbol', 'Close_Value'])\n",
    "\n",
    "# load and store the data for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_begin{symbol}.csv'\n",
    "    # read CSV file \n",
    "    df = pd.read_csv(output_file)\n",
    "\n",
    "    # Select the last row only\n",
    "    last_row = df.tail(1)\n",
    "\n",
    "     # Write symbol and close value to the data frame\n",
    "    data = {'Symbol': symbol, 'Close_Value': last_row['Close'].iloc[0]}\n",
    "    combined_data_begin = pd.concat([combined_data_begin, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "    \n",
    "# Add a row for the risk-free interest rate with the specified value\n",
    "risk_free_rate = 4 # Input in percentage\n",
    "risk_free_rate = risk_free_rate / 12 # Risk free rate per month\n",
    "risk_free_data = {'Symbol': 'Risk_Free', 'Close_Value': 100}\n",
    "combined_data_begin = combined_data_begin.append(risk_free_data, ignore_index=True)\n",
    "\n",
    "print(combined_data_begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69294cef",
   "metadata": {},
   "source": [
    "# read predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc05f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ALV.DE     DBK.DE    VOW3.DE     BMW.DE  \\\n",
      "prediction_20_days_ahead  145.755386  14.388221  85.346313  87.201279   \n",
      "\n",
      "                              ADS.DE      BEI.DE     DTE.SG     SAP.DE  \\\n",
      "prediction_20_days_ahead  108.782417  100.752472  20.497587  84.601852   \n",
      "\n",
      "                            1COV.DE     BAS.DE    EOAN.DE     RWE.DE  \n",
      "prediction_20_days_ahead  49.830753  50.684361  13.794801  31.657511  \n"
     ]
    }
   ],
   "source": [
    "# Define the name of the file\n",
    "json_file = 'settings/predictions_dict.json'\n",
    "\n",
    "# read array from the json file\n",
    "with open(json_file, 'r') as f:\n",
    "    predictions_dict = json.load(f)\n",
    "    \n",
    "# Convert predictions_dict to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions_dict)\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c4e0b",
   "metadata": {},
   "source": [
    "# add dividend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1372ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Share  Dividend\n",
      "0    ALV.DE     11.40\n",
      "1    DBK.DE      0.30\n",
      "2   VOW3.DE     27.82\n",
      "3    BMW.DE      8.50\n",
      "4    ADS.DE      0.70\n",
      "5    BEI.DE      0.70\n",
      "6    DTE.SG      0.70\n",
      "7    SAP.DE      2.05\n",
      "8   1COV.DE      0.00\n",
      "9    BAS.DE      3.40\n",
      "10  EOAN.DE      0.51\n",
      "11   RWE.DE      0.90\n",
      "      Share  Dividend\n",
      "0    ALV.DE  0.950000\n",
      "1    DBK.DE  0.025000\n",
      "2   VOW3.DE  2.318333\n",
      "3    BMW.DE  0.708333\n",
      "4    ADS.DE  0.058333\n",
      "5    BEI.DE  0.058333\n",
      "6    DTE.SG  0.058333\n",
      "7    SAP.DE  0.170833\n",
      "8   1COV.DE  0.000000\n",
      "9    BAS.DE  0.283333\n",
      "10  EOAN.DE  0.042500\n",
      "11   RWE.DE  0.075000\n",
      "                              ALV.DE     DBK.DE    VOW3.DE     BMW.DE  \\\n",
      "prediction_20_days_ahead  146.705386  14.413221  87.664647  87.909612   \n",
      "\n",
      "                              ADS.DE      BEI.DE     DTE.SG     SAP.DE  \\\n",
      "prediction_20_days_ahead  108.840751  100.810805  20.555921  84.772686   \n",
      "\n",
      "                            1COV.DE     BAS.DE    EOAN.DE     RWE.DE  \n",
      "prediction_20_days_ahead  49.830753  50.967694  13.837301  31.732511  \n"
     ]
    }
   ],
   "source": [
    "excel_file_path_div = 'settings/Dividend2023.xlsx'\n",
    "div = pd.read_excel(excel_file_path_div)\n",
    "print(div)\n",
    "# Divide all values by 12 in the column \"Dividend\"\n",
    "div['Dividend'] = div['Dividend'] / 12\n",
    "\n",
    "print(div)\n",
    "\n",
    "# set symbol column as index\n",
    "div.set_index('Share', inplace=True)\n",
    "\n",
    "# Add the dividend for every symbol in preditions_df\n",
    "for symbol in predictions_df.columns:\n",
    "    if symbol in div.index:\n",
    "        predictions_df[symbol] += div.loc[symbol, 'Dividend']\n",
    "\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70120db",
   "metadata": {},
   "source": [
    "# calculate return in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8900ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ALV.DE    DBK.DE    VOW3.DE     BMW.DE  \\\n",
      "prediction_20_days_ahead -47.190283 -1.157447 -28.635095 -17.810758   \n",
      "\n",
      "                             ADS.DE    BEI.DE    DTE.SG     SAP.DE   1COV.DE  \\\n",
      "prediction_20_days_ahead -47.419927 -25.29766 -8.375658 -53.024115 -1.675704   \n",
      "\n",
      "                            BAS.DE   EOAN.DE    RWE.DE  \n",
      "prediction_20_days_ahead -3.707362  7.390768  0.866216  \n"
     ]
    }
   ],
   "source": [
    "# Für jedes Symbol in predictions_df den entsprechenden Close_Value aus combined_data_begin abziehen\n",
    "for symbol in predictions_df.columns:\n",
    "    if symbol in combined_data_begin['Symbol'].values:\n",
    "        close_value = combined_data_begin.loc[combined_data_begin['Symbol'] == symbol, 'Close_Value'].values[0]\n",
    "        predictions_df[symbol] = ((predictions_df[symbol] - close_value) / close_value) * 100\n",
    "\n",
    "print(predictions_df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13e92b",
   "metadata": {},
   "source": [
    "# add risk free rate per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64cc122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ALV.DE    DBK.DE    VOW3.DE     BMW.DE  \\\n",
      "prediction_20_days_ahead -47.190283 -1.157447 -28.635095 -17.810758   \n",
      "\n",
      "                             ADS.DE    BEI.DE    DTE.SG     SAP.DE   1COV.DE  \\\n",
      "prediction_20_days_ahead -47.419927 -25.29766 -8.375658 -53.024115 -1.675704   \n",
      "\n",
      "                            BAS.DE   EOAN.DE    RWE.DE  Risk Free  \n",
      "prediction_20_days_ahead -3.707362  7.390768  0.866216   0.333333  \n"
     ]
    }
   ],
   "source": [
    "# Symbol für den risikofreien Zinssatz\n",
    "risk_free_symbol = 'Risk Free'\n",
    "\n",
    "# Erstellen einer neuen Zeile für den risikofreien Zinssatz\n",
    "risk_free_row = pd.DataFrame({risk_free_symbol: [(risk_free_rate)]}, index=['prediction_20_days_ahead'])\n",
    "\n",
    "# Anhängen der neuen Zeile an predictions_df\n",
    "predictions_df = predictions_df.join(risk_free_row)\n",
    "\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad3721",
   "metadata": {},
   "source": [
    "# read profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78181960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: 119.83800768359538\n"
     ]
    }
   ],
   "source": [
    "json_file_path = 'settings/profit.json'\n",
    "\n",
    "try:\n",
    "    # read JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        profit = data['profit']\n",
    "except FileNotFoundError:\n",
    "    # If the file can not be found, set the value of new_portfolio_value to 0\n",
    "    profit = 0\n",
    "\n",
    "print(f'Profit: {profit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38ceb3",
   "metadata": {},
   "source": [
    "# load share value from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f606101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startdatum: 2024-04-01, Enddatum: 2024-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start_date = start_date\n",
    "end_date = end_date\n",
    "print(f'Startdatum: {start_date}, Enddatum: {end_date}')\n",
    "# Load and store the symbols for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}_2019.csv'\n",
    "    download_stock_data(symbol, start_date, end_date, output_file)\n",
    "\n",
    "    # search and delete for empty rows in the CSV \n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the cleaned rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee54ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste der letzten Close-Werte:\n",
      "ALV.DE: 266.29998779296875\n",
      "DBK.DE: 15.104000091552734\n",
      "VOW3.DE: 120.75\n",
      "BMW.DE: 106.8000030517578\n",
      "ADS.DE: 232.3000030517578\n",
      "BEI.DE: 139.4499969482422\n",
      "DTE.SG: 21.71999931335449\n",
      "SAP.DE: 171.4199981689453\n",
      "1COV.DE: 47.54999923706055\n",
      "BAS.DE: 49.05500030517578\n",
      "EOAN.DE: 12.46500015258789\n",
      "RWE.DE: 33.0\n",
      "Risk_Free: 100.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# list for the last close value of the shares\n",
    "last_close_values = []\n",
    "\n",
    "# load for each symbol\n",
    "for symbol in stock_symbols:\n",
    "    # file name of the csv data\n",
    "    csv_file = f'stock_data_{symbol}_2019.csv'\n",
    "    \n",
    "    # load CSV data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # set date as index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # collect just the last close value and write it to the list\n",
    "    last_close_value = df['Close'].iloc[-1]\n",
    "    last_close_values.append((symbol, last_close_value))\n",
    "    \n",
    "# Add a row for the risk-free interest rate with a value of 1\n",
    "last_close_values.append(('Risk_Free', 100 + risk_free_rate))\n",
    "    \n",
    "# print the list\n",
    "print(\"Liste der letzten Close-Werte:\")\n",
    "for symbol, last_close_value in last_close_values:\n",
    "    print(f\"{symbol}: {last_close_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6215f",
   "metadata": {},
   "source": [
    "# Historic data from 2018 for the covarianz matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b131f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startdatum: 2023-10-01, Enddatum: 2024-03-31\n"
     ]
    }
   ],
   "source": [
    "excel_file_path = 'settings/lastSequenceForPrediction.xlsx'\n",
    "\n",
    "# path to the data, in which the index is stored\n",
    "index_file_path = 'settings/lastSequenceForPrediction.txt'\n",
    "\n",
    "# read the current index from the index file\n",
    "try:\n",
    "    with open(index_file_path, 'r') as index_file:\n",
    "        current_row_index = int(index_file.read().strip())\n",
    "except FileNotFoundError:\n",
    "    current_row_index = 0\n",
    "\n",
    "# read excel file\n",
    "df_lastSeq = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Check, if index is out of bounds\n",
    "if current_row_index >= len(df_lastSeq):\n",
    "    print(\"Es gibt keine weiteren Zeilen in der Excel-Tabelle.\")\n",
    "else:\n",
    "    # extract data from the current row\n",
    "    start_date_lastSeq = df_lastSeq.loc[current_row_index, 'start_date']\n",
    "    end_date_lastSeq = df_lastSeq.loc[current_row_index, 'end_date']\n",
    "    \n",
    "    # Output of the current data \n",
    "    print(f'Startdatum: {start_date_lastSeq}, Enddatum: {end_date_lastSeq}')\n",
    "\n",
    "    # Update the index in the index file for the next call\n",
    "    with open(index_file_path, 'w') as index_file:\n",
    "        index_file.write(str(current_row_index + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b06561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Definition of the time period\n",
    "start_date2018 = '2023-01-01'\n",
    "end_date2018 = end_date_lastSeq\n",
    "print(end_date2018)\n",
    "# Load and store the data for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}_2018.csv'\n",
    "    download_stock_data(symbol, start_date2018, end_date2018, output_file)\n",
    "\n",
    "    # Search and delete empty rows in the CSV file\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the cleaned rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf44c1",
   "metadata": {},
   "source": [
    "# Combine historical data to one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "effaa43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ALV.DE  DBK.DE     VOW3.DE      BMW.DE      ADS.DE  \\\n",
      "2023-01-02  203.050003  10.942  120.040001   85.800003  127.699997   \n",
      "2023-01-03  205.199997  11.112  122.059998   85.830002  131.880005   \n",
      "2023-01-04  211.500000  11.698  125.879997   87.879997  138.380005   \n",
      "2023-01-05  209.550003  11.494  127.120003   88.949997  138.539993   \n",
      "2023-01-06  211.800003  11.596  128.160004   89.529999  140.679993   \n",
      "...                ...     ...         ...         ...         ...   \n",
      "2024-03-22  271.850006  14.178  118.080002  104.120003  200.250000   \n",
      "2024-03-25  275.200012  14.146  119.379997  106.239998  203.949997   \n",
      "2024-03-26  277.000000  14.230  121.260002  106.559998  204.300003   \n",
      "2024-03-27  277.450012  14.612  121.760002  106.160004  204.699997   \n",
      "2024-03-28  277.799988  14.582  122.839996  106.959999  207.000000   \n",
      "\n",
      "                BEI.DE     DTE.SG      SAP.DE    1COV.DE     BAS.DE  EOAN.DE  \\\n",
      "2023-01-02  107.150002  18.910000   97.419998  38.259998  47.985001    9.468   \n",
      "2023-01-03  107.500000  19.056000   98.510002  39.580002  48.889999    9.656   \n",
      "2023-01-04  108.800003  19.184000  100.699997  41.470001  50.959999    9.992   \n",
      "2023-01-05  107.800003  19.507999  100.839996  41.709999  51.619999    9.796   \n",
      "2023-01-06  108.300003  19.754000  102.339996  42.369999  52.810001    9.878   \n",
      "...                ...        ...         ...        ...        ...      ...   \n",
      "2024-03-22  133.000000  21.905001  180.279999  50.580002  52.720001   12.455   \n",
      "2024-03-25  133.199997  22.010000  180.740005  50.660000  52.930000   12.575   \n",
      "2024-03-26  134.250000  22.155001  182.600006  49.910000  52.630001   12.760   \n",
      "2024-03-27  135.649994  22.420000  182.039993  50.240002  53.250000   12.850   \n",
      "2024-03-28  134.949997  22.434999  180.460007  50.680000  52.930000   12.885   \n",
      "\n",
      "               RWE.DE   Risk_Free  \n",
      "2023-01-02  41.590000  100.000000  \n",
      "2023-01-03  39.619999  100.001052  \n",
      "2023-01-04  38.669998  100.002103  \n",
      "2023-01-05  38.889999  100.003155  \n",
      "2023-01-06  39.139999  100.004206  \n",
      "...               ...         ...  \n",
      "2024-03-22  31.150000  100.329127  \n",
      "2024-03-25  31.170000  100.330179  \n",
      "2024-03-26  30.990000  100.331230  \n",
      "2024-03-27  31.490000  100.332282  \n",
      "2024-03-28  31.459999  100.333333  \n",
      "\n",
      "[318 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data frame for the combined data\n",
    "combined_historical2018_data = pd.DataFrame()\n",
    "\n",
    "# load and combine the data for each share\n",
    "for symbol in stock_symbols:\n",
    "    # file name for the csv file\n",
    "    csv_file = f'stock_data_{symbol}_2018.csv'\n",
    "    \n",
    "    # read CSV file and set date to index\n",
    "    df = pd.read_csv(csv_file, index_col='Date', parse_dates=True)\n",
    "    \n",
    "    # change name of the close column\n",
    "    df.rename(columns={'Close': symbol}, inplace=True)\n",
    "    \n",
    "    # write data to the combined file\n",
    "    combined_historical2018_data = pd.concat([combined_historical2018_data, df[symbol]], axis=1)\n",
    "\n",
    "# drop rows with NaN values\n",
    "combined_historical2018_data.dropna(inplace=True)\n",
    "\n",
    "# Initialize the initial and final values for \"Risk_Free\"\n",
    "risk_free_initial = 100\n",
    "risk_free_final = 100 + risk_free_rate\n",
    "\n",
    "# Create a series for \"Risk_Free\" with increasing values\n",
    "risk_free_values = np.linspace(risk_free_initial, risk_free_final, len(combined_historical2018_data))\n",
    "\n",
    "# Add the \"Risk_Free\" series to the DataFrame\n",
    "combined_historical2018_data['Risk_Free'] = risk_free_values\n",
    "\n",
    "# create a CSV file for the data\n",
    "combined_historical2018_data.to_csv('combined_historical2018_stock_data.csv')\n",
    "\n",
    "print(combined_historical2018_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428f38c",
   "metadata": {},
   "source": [
    "# Mean variance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4a0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_variance_optimization(expected_returns, covariance_matrix):\n",
    "    n = len(expected_returns)\n",
    "    initial_weights = np.array([1/n] * n)  # start weighs\n",
    "    bounds = [(0, 1)] * n  # weigh border (0-100% for each share)\n",
    "\n",
    "    # Minimize the negative sharpe ratio\n",
    "    def negative_sharpe(weights, expected_returns, covariance_matrix):\n",
    "        portfolio_return = np.dot(weights, expected_returns)\n",
    "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(covariance_matrix, weights)))\n",
    "        return -portfolio_return / portfolio_volatility\n",
    "\n",
    "    result = minimize(negative_sharpe, initial_weights, args=(expected_returns, covariance_matrix), bounds=bounds, constraints={'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718e459",
   "metadata": {},
   "source": [
    "# Portfilio allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fb99f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_portfolio(predictions, historical_data, initial_capital):\n",
    "    # Calculate expected returns based on the predictions\n",
    "    expected_returns = predictions.mean()\n",
    "    \n",
    "    # Calculate the covariance matrix of the returns\n",
    "    covariance_matrix = historical_data.cov()\n",
    "           \n",
    "    print (covariance_matrix)\n",
    "    \n",
    "    # Perform mean-variance optimization to obtain optimal weights\n",
    "    optimal_weights = mean_variance_optimization(expected_returns, covariance_matrix)\n",
    "\n",
    "    # Calculate the allocation of assets based on the optimal weights and the available capital\n",
    "    asset_allocation = initial_capital * optimal_weights\n",
    "\n",
    "    return asset_allocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea613d",
   "metadata": {},
   "source": [
    "# Calculate portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93ae54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119.8380076835954\n",
      "               ALV.DE     DBK.DE    VOW3.DE     BMW.DE      ADS.DE  \\\n",
      "ALV.DE     263.233687  16.722550 -36.220076   5.952651  172.491887   \n",
      "DBK.DE      16.722550   1.551082   0.318550  -0.659780    6.540290   \n",
      "VOW3.DE    -36.220076   0.318550  69.134268  19.760646  -63.554093   \n",
      "BMW.DE       5.952651  -0.659780  19.760646  34.572252   35.942541   \n",
      "ADS.DE     172.491887   6.540290 -63.554093  35.942541  272.479734   \n",
      "BEI.DE     107.009092   4.771363 -30.880760  10.627189   99.324278   \n",
      "DTE.SG      10.880760   0.681397  -0.801476  -0.534726    3.412920   \n",
      "SAP.DE     279.440764  14.954034 -53.869391  32.660143  250.691795   \n",
      "1COV.DE     46.889052   2.295622 -25.165169   0.619697   59.397072   \n",
      "BAS.DE       4.412254   1.647993  17.191130   1.362113  -12.713713   \n",
      "EOAN.DE      7.639689   0.216266  -2.472728   1.698286    9.464359   \n",
      "RWE.DE     -32.281946  -1.548413   9.245094  -1.032059  -21.514112   \n",
      "Risk_Free    1.251003   0.056769  -0.504171   0.075096    1.307821   \n",
      "\n",
      "               BEI.DE     DTE.SG      SAP.DE    1COV.DE     BAS.DE    EOAN.DE  \\\n",
      "ALV.DE     107.009092  10.880760  279.440764  46.889052   4.412254   7.639689   \n",
      "DBK.DE       4.771363   0.681397   14.954034   2.295622   1.647993   0.216266   \n",
      "VOW3.DE    -30.880760  -0.801476  -53.869391 -25.165169  17.191130  -2.472728   \n",
      "BMW.DE      10.627189  -0.534726   32.660143   0.619697   1.362113   1.698286   \n",
      "ADS.DE      99.324278   3.412920  250.691795  59.397072 -12.713713   9.464359   \n",
      "BEI.DE      72.536878   6.542058  147.171173  22.094798  -7.972791   5.717161   \n",
      "DTE.SG       6.542058   1.422328   12.105468  -0.166893   0.127622   0.517795   \n",
      "SAP.DE     147.171173  12.105468  391.154347  55.928827  -9.991205  11.315764   \n",
      "1COV.DE     22.094798  -0.166893   55.928827  24.995107  -5.751996   1.670873   \n",
      "BAS.DE      -7.972791   0.127622   -9.991205  -5.751996   9.927988  -0.736333   \n",
      "EOAN.DE      5.717161   0.517795   11.315764   1.670873  -0.736333   0.595711   \n",
      "RWE.DE     -13.374891  -0.740584  -45.040890  -7.267154   2.734606  -0.649803   \n",
      "Risk_Free    0.719413   0.045623    1.729951   0.373570  -0.132235   0.056307   \n",
      "\n",
      "              RWE.DE  Risk_Free  \n",
      "ALV.DE    -32.281946   1.251003  \n",
      "DBK.DE     -1.548413   0.056769  \n",
      "VOW3.DE     9.245094  -0.504171  \n",
      "BMW.DE     -1.032059   0.075096  \n",
      "ADS.DE    -21.514112   1.307821  \n",
      "BEI.DE    -13.374891   0.719413  \n",
      "DTE.SG     -0.740584   0.045623  \n",
      "SAP.DE    -45.040890   1.729951  \n",
      "1COV.DE    -7.267154   0.373570  \n",
      "BAS.DE      2.734606  -0.132235  \n",
      "EOAN.DE    -0.649803   0.056307  \n",
      "RWE.DE     10.284497  -0.214124  \n",
      "Risk_Free  -0.214124   0.009347  \n",
      "[0.00000000e+00 1.09330013e-06 9.29886445e-07 1.08828682e-07\n",
      " 0.00000000e+00 0.00000000e+00 7.93303130e-07 0.00000000e+00\n",
      " 7.68774434e-07 3.11312853e+01 1.02592491e+03 6.27817979e+01\n",
      " 1.59867218e-05]\n"
     ]
    }
   ],
   "source": [
    "initial_capital = 1000 + profit # 1000€ start capital\n",
    "print(initial_capital)\n",
    "# Calculate the portfolio allocation\n",
    "portfolio_allocation = allocate_portfolio(predictions_df, combined_historical2018_data, initial_capital)\n",
    "# print portfolio allocation\n",
    "print(portfolio_allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a5cb0",
   "metadata": {},
   "source": [
    "# Simulation for one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1703d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-----------------------------\n",
      "7.497600762796423e-08\n",
      "1.0933001266423498e-06\n",
      "1.0933001266423498e-06\n",
      "-----------------------------\n",
      "7.56989964845851e-09\n",
      "9.29886445094843e-07\n",
      "2.0231865717371927e-06\n",
      "-----------------------------\n",
      "1.0174708579761232e-09\n",
      "1.0882868203760375e-07\n",
      "2.1320152537747965e-06\n",
      "-----------------------------\n",
      "0.0\n",
      "0.0\n",
      "2.1320152537747965e-06\n",
      "-----------------------------\n",
      "0.0\n",
      "0.0\n",
      "2.1320152537747965e-06\n",
      "-----------------------------\n",
      "3.536006905536143e-08\n",
      "7.933031303727195e-07\n",
      "2.9253183841475162e-06\n",
      "-----------------------------\n",
      "0.0\n",
      "0.0\n",
      "2.9253183841475162e-06\n",
      "-----------------------------\n",
      "1.5169187629369437e-08\n",
      "7.687744336857118e-07\n",
      "3.694092817833228e-06\n",
      "-----------------------------\n",
      "0.5881595518622859\n",
      "31.13128525956284\n",
      "31.13128895365566\n",
      "-----------------------------\n",
      "79.62164501155934\n",
      "1025.9249141978903\n",
      "1057.056203151546\n",
      "-----------------------------\n",
      "1.9956071102031996\n",
      "62.78179785995978\n",
      "1119.8380010115059\n",
      "-----------------------------\n",
      "1.5986721774134995e-07\n",
      "1.5986721774134996e-05\n",
      "1119.8380169982277\n",
      "-----------------------------\n",
      "Gesamtwert des Portfolios am Ende des ersten Monats von 2019: 1119.8380169982277\n",
      "[0.0, 7.497600762796423e-08, 7.56989964845851e-09, 1.0174708579761232e-09, 0.0, 0.0, 3.536006905536143e-08, 0.0, 1.5169187629369437e-08, 0.5881595518622859, 79.62164501155934, 1.9956071102031996, 1.5986721774134995e-07]\n"
     ]
    }
   ],
   "source": [
    "# Initialisation of the portfolio\n",
    "portfolio_value = 0\n",
    "# initialize the list for the quantity of the shares, which have to be purchased\n",
    "shares_to_buy_list = []\n",
    "# Purchase the shares based on the allocations\n",
    "for i, allocation in enumerate(portfolio_allocation):\n",
    "    # Calculate the quantity of the shares, which should be purchased with this allocation\n",
    "    shares_to_buy = (allocation) / combined_data_begin['Close_Value'][i]\n",
    "    shares_to_buy_list.append(shares_to_buy)\n",
    "    print(shares_to_buy)\n",
    "\n",
    "    # Calculate the value of the stock of the purchased shares\n",
    "    value_of_stock = shares_to_buy * combined_data_begin['Close_Value'][i]\n",
    "    print(value_of_stock)\n",
    "    \n",
    "    # Add the value of the purchased share to the portfolio\n",
    "    portfolio_value += value_of_stock\n",
    "    print(portfolio_value)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "# Output of the total value of the portfolio at the end of the period to be predicted\n",
    "print(\"Gesamtwert des Portfolios am Ende des ersten Monats von 2019:\", portfolio_value)\n",
    "print(shares_to_buy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53ca2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266.29998779296875\n",
      "0.0\n",
      "0.0\n",
      "----------------------------\n",
      "15.104000091552734\n",
      "7.497600762796423e-08\n",
      "1.1324376260770303e-06\n",
      "----------------------------\n",
      "120.75\n",
      "7.56989964845851e-09\n",
      "2.0465030086283957e-06\n",
      "----------------------------\n",
      "106.8000030517578\n",
      "1.0174708579761232e-09\n",
      "2.1551688993653203e-06\n",
      "----------------------------\n",
      "232.3000030517578\n",
      "0.0\n",
      "2.1551688993653203e-06\n",
      "----------------------------\n",
      "139.4499969482422\n",
      "0.0\n",
      "2.1551688993653203e-06\n",
      "----------------------------\n",
      "21.71999931335449\n",
      "3.536006905536143e-08\n",
      "2.923189574967938e-06\n",
      "----------------------------\n",
      "171.4199981689453\n",
      "0.0\n",
      "2.923189574967938e-06\n",
      "----------------------------\n",
      "47.54999923706055\n",
      "1.5169187629369437e-08\n",
      "3.6444844351712827e-06\n",
      "----------------------------\n",
      "49.05500030517578\n",
      "0.5881595518622859\n",
      "28.85217064058092\n",
      "----------------------------\n",
      "12.46500015258789\n",
      "79.62164501155934\n",
      "1021.3359878589669\n",
      "----------------------------\n",
      "33.0\n",
      "1.9956071102031996\n",
      "1087.1910224956725\n",
      "----------------------------\n",
      "100.33333333333333\n",
      "1.5986721774134995e-07\n",
      "1087.1910385356834\n",
      "----------------------------\n",
      "Wert des Portfolios:\n",
      "1087.1910385356834\n"
     ]
    }
   ],
   "source": [
    "# Define portfolio value\n",
    "new_portfolio_value = 0\n",
    "# Loop over the indices of the two lists\n",
    "for i in range(len(shares_to_buy_list)):\n",
    "    # convert to float\n",
    "    last_close_value = float(last_close_values[i][1])\n",
    "    print(last_close_value)\n",
    "    print(shares_to_buy_list[i])\n",
    "    #Calculate the new value of the share and add the value to the list\n",
    "    new_portfolio_value += (last_close_value * shares_to_buy_list[i])\n",
    "    print(new_portfolio_value)\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "print(\"Wert des Portfolios:\")\n",
    "print(new_portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec264d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wert von profit wurde erfolgreich in settings/profit.json gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# just the profit, to store it\n",
    "profit = new_portfolio_value - 1000\n",
    "\n",
    "# path to JSON file\n",
    "json_file_path = 'settings/profit.json'\n",
    "\n",
    "# Create Dictionary with the value of new_portfolio_value\n",
    "data = {'profit': profit}\n",
    "\n",
    "# Write JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file)\n",
    "\n",
    "print(f'Wert von profit wurde erfolgreich in {json_file_path} gespeichert.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d3115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
