@article{Ernst2009,
author = {Ernst, Damien and Glavic, Mevludin and Member, Senior and Capitanescu, Florin and Wehenkel, Louis},
doi = {10.1109/TSMCB.2008.2007630},
file = {:media/truecrypt1/Doktorarbeit/Literatur/MPC/machine learning/comparison/ernst-SMC.pdf:pdf},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
number = {2},
pages = {517--529},
title = {{Control : A Comparison on a Power System Problem}},
url = {https://ieeexplore.ieee.org/document/4717266},
volume = {39},
year = {2009}
}
@article{Bertsekas2005,
abstract = {We survey some recent research directions within the field of approximate dynamic programming, with a particular emphasis on rollout algorithms and model predictive control (MPC). We argue that while they are motivated by different concerns, these two methodologies are closely connected, and the mathematical essence of their desirable properties (cost improvement and stability, respectively) is couched on the central dynamic programming idea of policy iteration. In particular, among other things, we show that the most common MPC schemes can be viewed as rollout algorithms and are related to policy iteration methods. Furthermore, we embed rollout and MPC within a new unifying suboptimal control framework, based on a concept of restricted or constrained structure policies, which contains these schemes as special cases. {\textcopyright} 2005 EUCA.},
author = {Bertsekas, Dimitri P.},
doi = {10.3166/ejc.11.310-334},
file = {:media/truecrypt1/Doktorarbeit/Literatur/MPC/machine learning/comparison/1-s2.0-S0947358005710402-main.pdf:pdf},
issn = {09473580},
journal = {European Journal of Control},
keywords = {Dynamic programming,Model predictive control,Rollout algorithm,Stochastic optimal control},
number = {4-5},
pages = {310--334},
publisher = {Elsevier},
title = {{Dynamic programming and suboptimal control: A survey from ADP to MPC}},
url = {http://dx.doi.org/10.3166/ejc.11.310-334},
volume = {11},
year = {2005}
}
@article{Hertneck2018,
abstract = {A supervised learning framework is proposed to approximate a model predictive controller (MPC) with reduced computational complexity and guarantees on stability and constraint satisfaction. The framework can be used for a wide class of nonlinear systems. Any standard supervised learning technique (e.g., neural networks) can be employed to approximate the MPC from samples. In order to obtain closed-loop guarantees for the learned MPC, a robust MPC design is combined with statistical learning bounds. The MPC design ensures robustness to inaccurate inputs within given bounds, and Hoeffding's Inequality is used to validate that the learned MPC satisfies these bounds with high confidence. The result is a closed-loop statistical guarantee on stability and constraint satisfaction for the learned MPC. The proposed learning-based MPC framework is illustrated on a nonlinear benchmark problem, for which we learn a neural network controller with guarantees.},
archivePrefix = {arXiv},
arxivId = {1806.04167},
author = {Hertneck, Michael and Kohler, Johannes and Trimpe, Sebastian and Allgower, Frank},
doi = {10.1109/LCSYS.2018.2843682},
eprint = {1806.04167},
file = {:media/truecrypt1/Doktorarbeit/Literatur/MPC/machine learning/stability guarantees/LearninganApproximateModelPredictiveControllerwithGuarantees.pdf:pdf},
issn = {24751456},
journal = {IEEE Control Systems Letters},
keywords = {Predictive control for nonlinear systems,constrained control,machine learning},
number = {3},
pages = {543--548},
title = {{Learning an Approximate Model Predictive Controller with Guarantees}},
url = {https://ieeexplore.ieee.org/document/8371312},
volume = {2},
year = {2018}
}
@inproceedings{Morinelly2016,
address = {Trondheim, Norway},
author = {Morinelly, Juan E and Ydstie, B Erik},
booktitle = {11th IFAC Symposium on Dynamics and Control of Process Systems},
doi = {10.1016/j.ifacol.2016.07.276},
file = {:media/truecrypt1/Doktorarbeit/Literatur/MPC/machine learning/0205.pdf:pdf},
keywords = {adaptive control,approximate dynamic programming,dual control,model predictive control,optimal control,reinforcement learning},
pages = {266--271},
publisher = {IEEE},
title = {{Dual MPC with Reinforcement Learning}},
url = {https://doi.org/10.1016/j.ifacol.2016.07.276},
year = {2016}
}
@article{Dal2011,
author = {Dal, Mauricio P and Raul, Pont and Teixeira, Wendell W and Lima, Daniel M},
doi = {10.1016/j.ifacol.2019.06.120},
file = {:media/truecrypt1/Doktorarbeit/Literatur/MPC/machine learning/gradient boost/1-s2.0-S240589631930206X-main-1.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
keywords = {architecture,binary decision systems,energy distribution,lambda,machine learning,markov models,predictive control,resource allocation,stochastic control},
number = {1},
pages = {550--555},
publisher = {Elsevier B.V.},
title = {{MPC with Machine Learning Applied to Resource Allocation Problem using Lambda Architecture}},
url = {https://doi.org/10.1016/j.ifacol.2019.06.120},
volume = {52},
year = {2011}
}
