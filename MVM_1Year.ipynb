{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19628bf5",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c450942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5927e",
   "metadata": {},
   "source": [
    "# function to download stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6f2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(stock_symbols, start_date, end_date, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write heading of the columns\n",
    "        f.write('Date,Open,High,Low,Close,Volume\\n')\n",
    "        # load share data for the time period needed\n",
    "        stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "        stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]  # Choose the right columns\n",
    "        stock_data.to_csv(f, header=False)  # Write the data to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea319ae",
   "metadata": {},
   "source": [
    "# Define the shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1782716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = ['ALV.DE', 'DBK.DE', 'VOW3.DE', 'BMW.DE', 'ADS.DE', 'BEI.DE', 'DTE.SG', 'SAP.DE', '1COV.DE', 'BAS.DE', 'EOAN.DE', 'RWE.DE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e64b8c",
   "metadata": {},
   "source": [
    "# Read start and end for the sequence, which will be predicted from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c7ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-01-01'\n",
    "end_date = '2019-12-31'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882aaec1",
   "metadata": {},
   "source": [
    "# Read close values at the begin of the time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057ba5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-27 00:00:00\n",
      "2018-12-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Definition of the time period\n",
    "# convert in to datetime objekt to substract days for the last day before this period\n",
    "start_date_obj = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_obj = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "# Substract 5 days for the new start_date and 1 day for the new end_date\n",
    "# In the next block the last date will be extracted \n",
    "new_start_date = start_date_obj - timedelta(days=5)\n",
    "new_end_date = start_date_obj - timedelta(days=1)\n",
    "\n",
    "print(new_start_date)\n",
    "print(new_end_date)\n",
    "\n",
    "# Load and store the data for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_begin{symbol}.csv'\n",
    "    download_stock_data(symbol, new_start_date, new_end_date, output_file)\n",
    "\n",
    "    # Search and delete empty rows in the CSV file\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the cleaned data\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288520ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Symbol  Close_Value\n",
      "0    ALV.DE   175.139999\n",
      "1    DBK.DE     6.967000\n",
      "2   VOW3.DE   138.919998\n",
      "3    BMW.DE    70.699997\n",
      "4    ADS.DE   182.399994\n",
      "5    BEI.DE    91.160004\n",
      "6    DTE.SG    13.690000\n",
      "7    SAP.DE    86.930000\n",
      "8   1COV.DE    43.180000\n",
      "9    BAS.DE    60.400002\n",
      "10  EOAN.DE     8.627000\n",
      "11   RWE.DE    18.965000\n"
     ]
    }
   ],
   "source": [
    "# create data frame for the collected data \n",
    "combined_data_begin = pd.DataFrame(columns=['Symbol', 'Close_Value'])\n",
    "\n",
    "# load and store the data for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_begin{symbol}.csv'\n",
    "    # read CSV file \n",
    "    df = pd.read_csv(output_file)\n",
    "\n",
    "    # Select the last row only\n",
    "    last_row = df.tail(1)\n",
    "\n",
    "     # Write symbol and close value to the data frame\n",
    "    data = {'Symbol': symbol, 'Close_Value': last_row['Close'].iloc[0]}\n",
    "    combined_data_begin = pd.concat([combined_data_begin, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "\n",
    "print(combined_data_begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69294cef",
   "metadata": {},
   "source": [
    "# read predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc05f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ALV.DE     DBK.DE    VOW3.DE     BMW.DE  \\\n",
      "prediction_20_days_ahead  50.421959  14.869346  29.790468  39.409405   \n",
      "\n",
      "                             ADS.DE   BEI.DE     DTE.SG     SAP.DE    1COV.DE  \\\n",
      "prediction_20_days_ahead  71.390404  23.6108  15.274905  31.452709  12.450314   \n",
      "\n",
      "                             BAS.DE    EOAN.DE     RWE.DE  \n",
      "prediction_20_days_ahead  41.113701  11.716145  18.942484  \n"
     ]
    }
   ],
   "source": [
    "# Define the name of the file\n",
    "json_file = 'settings/predictions1Year_dict.json'\n",
    "\n",
    "# read array from the json file\n",
    "with open(json_file, 'r') as f:\n",
    "    predictions_dict = json.load(f)\n",
    "    \n",
    "# Convert predictions_dict to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions_dict)\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6e4bc",
   "metadata": {},
   "source": [
    "# Calculate return in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5eaaf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ALV.DE      DBK.DE    VOW3.DE     BMW.DE  \\\n",
      "prediction_20_days_ahead -71.210484  113.425372 -78.555666 -44.258265   \n",
      "\n",
      "                             ADS.DE     BEI.DE     DTE.SG     SAP.DE  \\\n",
      "prediction_20_days_ahead -60.860523 -74.099606  11.577105 -63.818349   \n",
      "\n",
      "                            1COV.DE     BAS.DE    EOAN.DE    RWE.DE  \n",
      "prediction_20_days_ahead -71.166481 -31.930961  35.807868 -0.118725  \n"
     ]
    }
   ],
   "source": [
    "# FÃ¼r jedes Symbol in predictions_df den entsprechenden Close_Value aus combined_data_begin abziehen\n",
    "for symbol in predictions_df.columns:\n",
    "    if symbol in combined_data_begin['Symbol'].values:\n",
    "        close_value = combined_data_begin.loc[combined_data_begin['Symbol'] == symbol, 'Close_Value'].values[0]\n",
    "        predictions_df[symbol] = ((predictions_df[symbol] - close_value) / close_value) * 100\n",
    "\n",
    "print(predictions_df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38ceb3",
   "metadata": {},
   "source": [
    "# load share value from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f606101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startdatum: 2019-01-01, Enddatum: 2019-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start_date = start_date\n",
    "end_date = end_date\n",
    "print(f'Startdatum: {start_date}, Enddatum: {end_date}')\n",
    "# Load and store the symbols for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}_2019.csv'\n",
    "    download_stock_data(symbol, start_date, end_date, output_file)\n",
    "\n",
    "    # search and delete for empty rows in the CSV \n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the cleaned rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee54ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.3999938964844\n",
      "Liste der letzten Close-Werte:\n",
      "ALV.DE: 218.3999938964844\n",
      "DBK.DE: 6.916999816894531\n",
      "VOW3.DE: 176.24000549316406\n",
      "BMW.DE: 73.13999938964844\n",
      "ADS.DE: 289.79998779296875\n",
      "BEI.DE: 106.6500015258789\n",
      "DTE.SG: 13.6899995803833\n",
      "SAP.DE: 120.31999969482422\n",
      "1COV.DE: 41.45000076293945\n",
      "BAS.DE: 67.3499984741211\n",
      "EOAN.DE: 9.52400016784668\n",
      "RWE.DE: 27.350000381469727\n"
     ]
    }
   ],
   "source": [
    "# list for the las close value of the shares\n",
    "last_close_values = []\n",
    "\n",
    "# load for each symbol\n",
    "for symbol in stock_symbols:\n",
    "    # file name of the csv data\n",
    "    csv_file = f'stock_data_{symbol}_2019.csv'\n",
    "    \n",
    "    # load CSV data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # set date as index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # collect just the last close value and write it to the list\n",
    "    last_close_value = df['Close'].iloc[-1]\n",
    "    last_close_values.append((symbol, last_close_value))\n",
    "print(last_close_values[0][1])\n",
    "# print the list\n",
    "print(\"Liste der letzten Close-Werte:\")\n",
    "for symbol, last_close_value in last_close_values:\n",
    "    print(f\"{symbol}: {last_close_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6215f",
   "metadata": {},
   "source": [
    "# Historic data from 2018 for the covarianz matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b06561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Definition of the time period\n",
    "start_date2018 = '2018-01-01'\n",
    "end_date2018 = '2018-12-31'\n",
    "print(end_date2018)\n",
    "# Load and store the data for every symbol (share)\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}_2018.csv'\n",
    "    download_stock_data(symbol, start_date2018, end_date2018, output_file)\n",
    "\n",
    "    # Search and delete empty rows in the CSV file\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the cleaned rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf44c1",
   "metadata": {},
   "source": [
    "# Combine historical data to one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "effaa43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ALV.DE     DBK.DE     VOW3.DE     BMW.DE      ADS.DE  \\\n",
      "2018-01-02  192.699997  15.958000  165.699997  86.400002  167.149994   \n",
      "2018-01-03  193.000000  15.910000  171.440002  86.860001  168.050003   \n",
      "2018-01-04  195.500000  16.332001  174.440002  87.480003  170.250000   \n",
      "2018-01-05  198.559998  15.490000  179.199997  88.500000  172.050003   \n",
      "2018-01-08  198.860001  15.340000  179.839996  89.669998  172.750000   \n",
      "...                ...        ...         ...        ...         ...   \n",
      "2018-12-19  175.940002   7.530000  146.880005  73.449997  187.050003   \n",
      "2018-12-20  174.960007   7.000000  143.899994  71.839996  183.750000   \n",
      "2018-12-21  175.020004   7.042000  143.300003  71.930000  184.750000   \n",
      "2018-12-27  172.160004   6.750000  137.440002  69.860001  180.100006   \n",
      "2018-12-28  175.139999   6.967000  138.919998  70.699997  182.399994   \n",
      "\n",
      "                BEI.DE  DTE.SG     SAP.DE    1COV.DE     BAS.DE  EOAN.DE  \\\n",
      "2018-01-02   96.199997  14.872  92.800003  85.639999  91.309998    9.078   \n",
      "2018-01-03   96.680000  14.835  94.070000  86.760002  91.580002    9.086   \n",
      "2018-01-04   98.059998  14.890  95.089996  88.419998  93.550003    9.109   \n",
      "2018-01-05   99.279999  14.940  96.440002  88.300003  94.849998    9.237   \n",
      "2018-01-08  100.300003  15.040  96.269997  87.199997  95.010002    9.208   \n",
      "...                ...     ...        ...        ...        ...      ...   \n",
      "2018-12-19   93.059998  13.690  89.220001  43.150002  60.340000    8.965   \n",
      "2018-12-20   92.760002  13.690  87.769997  41.900002  59.750000    8.895   \n",
      "2018-12-21   92.739998  13.690  86.419998  43.279999  60.720001    8.864   \n",
      "2018-12-27   90.559998  13.690  85.790001  42.130001  59.669998    8.524   \n",
      "2018-12-28   91.160004  13.690  86.930000  43.180000  60.400002    8.627   \n",
      "\n",
      "               RWE.DE  \n",
      "2018-01-02  17.299999  \n",
      "2018-01-03  17.459999  \n",
      "2018-01-04  17.465000  \n",
      "2018-01-05  17.639999  \n",
      "2018-01-08  17.780001  \n",
      "...               ...  \n",
      "2018-12-19  19.320000  \n",
      "2018-12-20  19.155001  \n",
      "2018-12-21  19.094999  \n",
      "2018-12-27  18.490000  \n",
      "2018-12-28  18.965000  \n",
      "\n",
      "[252 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data frame for the combined data\n",
    "combined_historical2018_data = pd.DataFrame()\n",
    "\n",
    "# load and combine the data for each share\n",
    "for symbol in stock_symbols:\n",
    "    # file name for the csv file\n",
    "    csv_file = f'stock_data_{symbol}_2018.csv'\n",
    "    \n",
    "    # read CSV file and set date to index\n",
    "    df = pd.read_csv(csv_file, index_col='Date', parse_dates=True)\n",
    "    \n",
    "    # change name of the close column\n",
    "    df.rename(columns={'Close': symbol}, inplace=True)\n",
    "    \n",
    "    # write data to the combined file\n",
    "    combined_historical2018_data = pd.concat([combined_historical2018_data, df[symbol]], axis=1)\n",
    "\n",
    "# drop rows with NaN values\n",
    "combined_historical2018_data.dropna(inplace=True)\n",
    "    \n",
    "# create a CSV file for the data\n",
    "combined_historical2018_data.to_csv('combined_historical2018_stock_data.csv')\n",
    "\n",
    "print(combined_historical2018_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428f38c",
   "metadata": {},
   "source": [
    "# Mean variance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4a0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_variance_optimization(expected_returns, covariance_matrix):\n",
    "    n = len(expected_returns)\n",
    "    initial_weights = np.array([1/n] * n)  # start weighs\n",
    "    bounds = [(0, 1)] * n  # weigh border (0-100% for each share)\n",
    "\n",
    "    # Minimize the negative sharpe ratio\n",
    "    def negative_sharpe(weights, expected_returns, covariance_matrix):\n",
    "        portfolio_return = np.dot(weights, expected_returns)\n",
    "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(covariance_matrix, weights)))\n",
    "        return -portfolio_return / portfolio_volatility\n",
    "\n",
    "    result = minimize(negative_sharpe, initial_weights, args=(expected_returns, covariance_matrix), bounds=bounds, constraints={'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718e459",
   "metadata": {},
   "source": [
    "# Portfilio allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb99f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_portfolio(predictions, historical_data, initial_capital):\n",
    "    # Calculate expected returns based on the predictions\n",
    "    expected_returns = predictions.mean()\n",
    "    \n",
    "    # Calculate the covariance matrix of the returns\n",
    "    covariance_matrix = historical_data.cov()\n",
    "    \n",
    "    # Perform mean-variance optimization to obtain optimal weights\n",
    "    optimal_weights = mean_variance_optimization(expected_returns, covariance_matrix)\n",
    "\n",
    "    # Calculate the allocation of assets based on the optimal weights and the available capital\n",
    "    asset_allocation = initial_capital * optimal_weights\n",
    "\n",
    "    return asset_allocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea613d",
   "metadata": {},
   "source": [
    "# Calculate portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93ae54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[1.13166176e-07 1.51256776e+02 3.30266124e-07 1.50661152e-07\n",
      " 8.93798226e+00 1.47354927e-05 1.81694249e-04 1.80577688e-05\n",
      " 6.40847335e-07 3.88575039e-07 8.39805823e+02 1.28824550e-04]\n"
     ]
    }
   ],
   "source": [
    "initial_capital = 1000 # 1000â¬ start capital\n",
    "print(initial_capital)\n",
    "# Calculate the portfolio allocation\n",
    "portfolio_allocation = allocate_portfolio(predictions_df, combined_historical2018_data, initial_capital)\n",
    "# print portfolio allocation\n",
    "print(portfolio_allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f77c6",
   "metadata": {},
   "source": [
    "# Simulation for one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1703d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.461469458945479e-10\n",
      "1.1316617570959432e-07\n",
      "1.1316617570959432e-07\n",
      "-----------------------------\n",
      "21.710460134700476\n",
      "151.25677592409588\n",
      "151.25677603726206\n",
      "-----------------------------\n",
      "2.377383592489947e-09\n",
      "3.30266124315584e-07\n",
      "151.25677636752818\n",
      "-----------------------------\n",
      "2.1309923466263185e-09\n",
      "1.5066115240320817e-07\n",
      "151.25677651818933\n",
      "-----------------------------\n",
      "0.04900209738686987\n",
      "8.937982264279999\n",
      "160.19475878246934\n",
      "-----------------------------\n",
      "1.6164427473497068e-07\n",
      "1.473549267679894e-05\n",
      "160.194773517962\n",
      "-----------------------------\n",
      "1.3272041981306533e-05\n",
      "0.00018169424915491598\n",
      "160.19495521221117\n",
      "-----------------------------\n",
      "2.0772769724633339e-07\n",
      "1.8057768785017224e-05\n",
      "160.19497326997995\n",
      "-----------------------------\n",
      "1.4841299924240664e-08\n",
      "6.408473352579171e-07\n",
      "160.1949739108273\n",
      "-----------------------------\n",
      "6.433361415471675e-09\n",
      "3.8857503931101965e-07\n",
      "160.19497429940233\n",
      "-----------------------------\n",
      "97.34621965590765\n",
      "839.8058228603537\n",
      "1000.0007971597561\n",
      "-----------------------------\n",
      "6.7927523757088236e-06\n",
      "0.0001288245498418096\n",
      "1000.0009259843059\n",
      "-----------------------------\n",
      "Gesamtwert des Portfolios am Ende des ersten Monats von 2019: 1000.0009259843059\n",
      "[6.461469458945479e-10, 21.710460134700476, 2.377383592489947e-09, 2.1309923466263185e-09, 0.04900209738686987, 1.6164427473497068e-07, 1.3272041981306533e-05, 2.0772769724633339e-07, 1.4841299924240664e-08, 6.433361415471675e-09, 97.34621965590765, 6.7927523757088236e-06]\n"
     ]
    }
   ],
   "source": [
    "# Initialisation of the portfolio\n",
    "portfolio_value = 0\n",
    "# initialize the list for the quantity of the shares, which have to be purchased\n",
    "shares_to_buy_list = []\n",
    "# Purchase the shares based on the allocations\n",
    "for i, allocation in enumerate(portfolio_allocation):\n",
    "    # Calculate the quantity of the shares, which should be purchased with this allocation\n",
    "    shares_to_buy = (allocation) / combined_data_begin['Close_Value'][i]\n",
    "    shares_to_buy_list.append(shares_to_buy)\n",
    "    print(shares_to_buy)\n",
    "\n",
    "    # Calculate the value of the stock of the purchased shares\n",
    "    value_of_stock = shares_to_buy * combined_data_begin['Close_Value'][i]\n",
    "    print(value_of_stock)\n",
    "    \n",
    "    # Add the value of the purchased share to the portfolio\n",
    "    portfolio_value += value_of_stock\n",
    "    print(portfolio_value)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "# Output of the total value of the portfolio at the end of the period to be predicted\n",
    "print(\"Gesamtwert des Portfolios am Ende des ersten Monats von 2019:\", portfolio_value)\n",
    "print(shares_to_buy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53ca2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.3999938964844\n",
      "6.461469458945479e-10\n",
      "1.4111848903960129e-07\n",
      "----------------------------\n",
      "6.916999816894531\n",
      "21.710460134700476\n",
      "150.1712489175377\n",
      "----------------------------\n",
      "176.24000549316406\n",
      "2.377383592489947e-09\n",
      "150.17124933652778\n",
      "----------------------------\n",
      "73.13999938964844\n",
      "2.1309923466263185e-09\n",
      "150.17124949238857\n",
      "----------------------------\n",
      "289.79998779296875\n",
      "0.04900209738686987\n",
      "164.37205671693332\n",
      "----------------------------\n",
      "106.6500015258789\n",
      "1.6164427473497068e-07\n",
      "164.37207395629545\n",
      "----------------------------\n",
      "13.6899995803833\n",
      "1.3272041981306533e-05\n",
      "164.37225565054462\n",
      "----------------------------\n",
      "120.31999969482422\n",
      "2.0772769724633339e-07\n",
      "164.3722806443411\n",
      "----------------------------\n",
      "41.45000076293945\n",
      "1.4841299924240664e-08\n",
      "164.372281259513\n",
      "----------------------------\n",
      "67.3499984741211\n",
      "6.433361415471675e-09\n",
      "164.37228169279987\n",
      "----------------------------\n",
      "9.52400016784668\n",
      "97.34621965590765\n",
      "1091.497694034904\n",
      "----------------------------\n",
      "27.350000381469727\n",
      "6.7927523757088236e-06\n",
      "1091.4978798166842\n",
      "----------------------------\n",
      "Wert des Portfolios:\n",
      "1091.4978798166842\n"
     ]
    }
   ],
   "source": [
    "# Define portfolio value\n",
    "new_portfolio_value = 0\n",
    "# Loop over the indices of the two lists\n",
    "for i in range(len(shares_to_buy_list)):\n",
    "    # convert to float\n",
    "    last_close_value = float(last_close_values[i][1])\n",
    "    print(last_close_value)\n",
    "    print(shares_to_buy_list[i])\n",
    "    #Calculate the new value of the share and add the value to the list\n",
    "    new_portfolio_value += (last_close_value * shares_to_buy_list[i])\n",
    "    print(new_portfolio_value)\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "print(\"Wert des Portfolios:\")\n",
    "print(new_portfolio_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
