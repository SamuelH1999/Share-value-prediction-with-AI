{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac4dcf2",
   "metadata": {},
   "source": [
    "# Import librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64238bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "import yfinance as yf\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69186c2e",
   "metadata": {},
   "source": [
    "# read predicting sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a46dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(stock_symbols, start_date, end_date, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        # write column headings\n",
    "        f.write('Date,Open,High,Low,Close,Volume\\n')\n",
    "        \n",
    "        #for symbol in stock_symbols:\n",
    "            # load share data for the symbol (Share name) and the given time period\n",
    "        stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "        stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]  # Auswahl der gewünschten Spalten\n",
    "        stock_data.to_csv(f, header=False)  # Schreiben der Daten in die Datei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50633fe",
   "metadata": {},
   "source": [
    "# load time sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074f3def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Enter symbols\n",
    "stock_symbols = ['ALV.DE', 'DBK.DE', 'VOW3.DE', 'BMW.DE', 'ADS.DE', 'BEI.DE', 'DTE.SG', 'SAP.DE', '1COV.DE', 'BAS.DE', 'EOAN.DE', 'RWE.DE']\n",
    "start_date = '2018-10-01'\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "# load and store the data for every share\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}.csv'\n",
    "    download_stock_data(symbol, start_date, end_date, output_file)\n",
    "\n",
    "    # read CSV and select select the desired columns\n",
    "    df = pd.read_csv(output_file, usecols=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    \n",
    "    # Search CSV file for empty lines and remove them\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # filter the empty lines\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the adjusted rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e1a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data frames for different symbols in the dictionary\n",
    "dfPre = {}\n",
    "\n",
    "for symbol in stock_symbols:\n",
    "    # load CSV\n",
    "    dfPre[symbol] = pd.read_csv(f'stock_data_{symbol}.csv')\n",
    "\n",
    "    # Drop empty rows\n",
    "    dfPre[symbol].dropna(inplace=True)\n",
    "\n",
    "    # transform date to index\n",
    "    dfPre[symbol].set_index('Date', inplace=True)\n",
    "\n",
    "    # Check the number of rows\n",
    "    num_rows = dfPre[symbol].shape[0]\n",
    "\n",
    "    # If more than 60 rows, keep the last 60 rows\n",
    "    if num_rows > 60:\n",
    "        dfPre[symbol] = dfPre[symbol].tail(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63ed050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor der Behandlung für ALV.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für ALV.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für DBK.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für DBK.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für VOW3.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für VOW3.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für BMW.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für BMW.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für ADS.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für ADS.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für BEI.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für BEI.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für DTE.SG gefunden: False\n",
      "Fehlende Werte nach der Behandlung für DTE.SG gefunden: False\n",
      "Fehlende Werte vor der Behandlung für SAP.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für SAP.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für 1COV.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für 1COV.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für BAS.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für BAS.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für EOAN.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für EOAN.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für RWE.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für RWE.DE gefunden: False\n",
      "Länge des Datensatzes für ALV.DE: 60\n",
      "Länge des Datensatzes für DBK.DE: 60\n",
      "Länge des Datensatzes für VOW3.DE: 60\n",
      "Länge des Datensatzes für BMW.DE: 60\n",
      "Länge des Datensatzes für ADS.DE: 60\n",
      "Länge des Datensatzes für BEI.DE: 60\n",
      "Länge des Datensatzes für DTE.SG: 60\n",
      "Länge des Datensatzes für SAP.DE: 60\n",
      "Länge des Datensatzes für 1COV.DE: 60\n",
      "Länge des Datensatzes für BAS.DE: 60\n",
      "Länge des Datensatzes für EOAN.DE: 60\n",
      "Länge des Datensatzes für RWE.DE: 60\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_values_beforePre = {symbol: dfPre[symbol].isnull().values.any() for symbol in stock_symbols}\n",
    "\n",
    "# missing values are replaced with teh mean of the row before and after the actual row\n",
    "for symbol in stock_symbols:\n",
    "    for column in dfPre[symbol].columns:\n",
    "        missing_valuesPre = dfPre[symbol][column].isnull()\n",
    "        dfPre[symbol].loc[missing_valuesPre, column] = (dfPre[symbol][column].shift() + dfPre[symbol][column].shift(-1)) / 2\n",
    "\n",
    "# Check if there are still any missing values \n",
    "missing_values_afterPre = {symbol: dfPre[symbol].isnull().values.any() for symbol in stock_symbols}\n",
    "\n",
    "# Output of the missing values before and after the Treatment\n",
    "for symbol in stock_symbols:\n",
    "    print(f\"Fehlende Werte vor der Behandlung für {symbol} gefunden:\", missing_values_beforePre[symbol])\n",
    "    print(f\"Fehlende Werte nach der Behandlung für {symbol} gefunden:\", missing_values_afterPre[symbol])\n",
    "\n",
    "# Output of the length of the data frame for all symbols\n",
    "for symbol in stock_symbols:\n",
    "    print(f\"Länge des Datensatzes für {symbol}:\", len(dfPre[symbol]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6894f0f",
   "metadata": {},
   "source": [
    "# Data normalization prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda529dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scaler\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "    \n",
    "# min-max scale factors\n",
    "min_value = scaler.data_min_\n",
    "max_value = scaler.data_max_\n",
    "# normalize the data for all symbols\n",
    "nfPre = {}\n",
    "nfPre_normalized = {}\n",
    "for symbol in stock_symbols:\n",
    "    # Copy the data fram and remove the column \"Date\" for every symbol\n",
    "    nfPre[symbol] = dfPre[symbol].copy()\n",
    "    \n",
    "    # Remove the index name \n",
    "    nfPre[symbol].index.name = None\n",
    "\n",
    "    # normalize the data for every symbol, except for the date (Index)\n",
    "    nfPre_normalized[symbol] = scaler.transform(nfPre[symbol])\n",
    "\n",
    "    # Create a new data frame with the normalized data and the original index for every symbol\n",
    "    nfPre[symbol] = pd.DataFrame(nfPre_normalized[symbol], columns=nfPre[symbol].columns, index=nfPre[symbol].index)\n",
    "\n",
    "    # Convert DataFrame to NumPy array for every symbol\n",
    "    nfPre[symbol] = nfPre[symbol].to_numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92ed14",
   "metadata": {},
   "source": [
    "# Daten preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a8ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store X_pre for every symbol in the dictionary\n",
    "X_pre_dict = {}\n",
    "\n",
    "# Iterate over each symbol\n",
    "for symbol in stock_symbols:\n",
    "    \n",
    "    nfPre_symbol = nfPre[symbol]\n",
    "    \n",
    "    # Define size for the current symbol\n",
    "    nfPre_size_symbol = len(nfPre_symbol)\n",
    "    \n",
    "    # Add external dimension\n",
    "    X_pre_symbol = np.expand_dims(nfPre_symbol[:nfPre_size_symbol], axis=0)\n",
    "    \n",
    "    # Transform to Tensor\n",
    "    X_pre_symbol_tensor = tf.convert_to_tensor(X_pre_symbol, dtype=tf.float32)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    X_pre_dict[symbol] = X_pre_symbol_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4c911",
   "metadata": {},
   "source": [
    "# Model importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c34d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = {}\n",
    "\n",
    "for symbol in stock_symbols:\n",
    "    # Load the stored model\n",
    "    loaded_models[symbol] = load_model(f'Predict1Year_{symbol}.h5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa84085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALV.DE': <Sequential name=sequential, built=True>, 'DBK.DE': <Sequential name=sequential, built=True>, 'VOW3.DE': <Sequential name=sequential, built=True>, 'BMW.DE': <Sequential name=sequential, built=True>, 'ADS.DE': <Sequential name=sequential, built=True>, 'BEI.DE': <Sequential name=sequential, built=True>, 'DTE.SG': <Sequential name=sequential, built=True>, 'SAP.DE': <Sequential name=sequential, built=True>, '1COV.DE': <Sequential name=sequential, built=True>, 'BAS.DE': <Sequential name=sequential, built=True>, 'EOAN.DE': <Sequential name=sequential, built=True>, 'RWE.DE': <Sequential name=sequential, built=True>}\n"
     ]
    }
   ],
   "source": [
    "print(loaded_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90458c92",
   "metadata": {},
   "source": [
    "# Prediction for the unkonown sequence and transform back into monetary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32404dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(symbol):\n",
    "    # Predict the current share(symbol)\n",
    "    predictions = loaded_models[symbol].predict(X_pre_dict[symbol])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0c7e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "Zurücktransformierte Vorhersagen für ALV.DE:\n",
      "[[4.8477291e+01 5.2120399e+01 4.6384171e+01 5.0421959e+01 6.6842765e+06]]\n",
      "50.42196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "Zurücktransformierte Vorhersagen für DBK.DE:\n",
      "[[1.5262897e+01 1.4950180e+01 1.4969557e+01 1.4869346e+01 1.0243163e+07]]\n",
      "14.869346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "Zurücktransformierte Vorhersagen für VOW3.DE:\n",
      "[[2.9207436e+01 2.8997992e+01 3.0793690e+01 2.9790468e+01 8.0602840e+06]]\n",
      "29.790468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "Zurücktransformierte Vorhersagen für BMW.DE:\n",
      "[[3.5927021e+01 3.5524639e+01 3.5756874e+01 3.9409405e+01 1.6885944e+07]]\n",
      "39.409405\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028B6DB7ECB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "Zurücktransformierte Vorhersagen für ADS.DE:\n",
      "[[ 8.080512e+01  8.132944e+01  6.626281e+01  7.139040e+01 -5.585156e+07]]\n",
      "71.3904\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028B6E2F0F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "Zurücktransformierte Vorhersagen für BEI.DE:\n",
      "[[2.5599476e+01 2.6736332e+01 2.5497450e+01 2.3610800e+01 2.4783056e+07]]\n",
      "23.6108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "Zurücktransformierte Vorhersagen für DTE.SG:\n",
      "[[1.6406565e+01 1.4333040e+01 6.2873535e+00 1.5274905e+01 1.6435672e+06]]\n",
      "15.274905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Zurücktransformierte Vorhersagen für SAP.DE:\n",
      "[[3.2544598e+01 3.1660706e+01 3.1477352e+01 3.1452709e+01 1.6659152e+07]]\n",
      "31.45271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "Zurücktransformierte Vorhersagen für 1COV.DE:\n",
      "[[1.2551546e+01 1.2640683e+01 1.1276700e+01 1.2450314e+01 7.1022745e+06]]\n",
      "12.450314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "Zurücktransformierte Vorhersagen für BAS.DE:\n",
      "[[4.1077271e+01 3.9804962e+01 4.0225788e+01 4.1113701e+01 2.2130022e+06]]\n",
      "41.1137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "Zurücktransformierte Vorhersagen für EOAN.DE:\n",
      "[[1.1633104e+01 1.2687147e+01 1.1997020e+01 1.1716145e+01 6.6882495e+06]]\n",
      "11.716145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Zurücktransformierte Vorhersagen für RWE.DE:\n",
      "[[1.8994858e+01 1.8683916e+01 1.8590775e+01 1.8942484e+01 7.7773330e+06]]\n",
      "18.942484\n",
      "{'ALV.DE': {'prediction_20_days_ahead': 50.42196}, 'DBK.DE': {'prediction_20_days_ahead': 14.869346}, 'VOW3.DE': {'prediction_20_days_ahead': 29.790468}, 'BMW.DE': {'prediction_20_days_ahead': 39.409405}, 'ADS.DE': {'prediction_20_days_ahead': 71.3904}, 'BEI.DE': {'prediction_20_days_ahead': 23.6108}, 'DTE.SG': {'prediction_20_days_ahead': 15.274905}, 'SAP.DE': {'prediction_20_days_ahead': 31.45271}, '1COV.DE': {'prediction_20_days_ahead': 12.450314}, 'BAS.DE': {'prediction_20_days_ahead': 41.1137}, 'EOAN.DE': {'prediction_20_days_ahead': 11.716145}, 'RWE.DE': {'prediction_20_days_ahead': 18.942484}}\n"
     ]
    }
   ],
   "source": [
    "# create dictionary to store the prediction for every symbol\n",
    "predictions_dict = {}\n",
    "predictions = {}\n",
    "\n",
    "# Iterate over every symbol\n",
    "for symbol in stock_symbols:\n",
    "\n",
    "    # Prediction for the actual symbol\n",
    "    predictions[symbol] = prediction(symbol)\n",
    "\n",
    "    # Inverse transformation of the prediction\n",
    "    predictions_original_scale_symbol = scaler.inverse_transform(predictions[symbol])\n",
    "\n",
    "    # extract the prediction 20 days in the future\n",
    "    prediction_20_days_ahead_symbol = predictions_original_scale_symbol[0][-2]\n",
    "\n",
    "    # store the prediction for the current symbol\n",
    "    predictions_dict[symbol] = {\n",
    "        'prediction_20_days_ahead': prediction_20_days_ahead_symbol\n",
    "    }\n",
    "\n",
    "    # Output the values of the inverse transformation\n",
    "    print(f\"Zurücktransformierte Vorhersagen für {symbol}:\")\n",
    "    print(predictions_original_scale_symbol)\n",
    "    print(prediction_20_days_ahead_symbol)\n",
    "print(predictions_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a4f65",
   "metadata": {},
   "source": [
    "# read test CSV from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fed4224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01\n",
      "2019-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# time period\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2019-12-31'\n",
    "print(start_date)\n",
    "print(end_date)\n",
    "\n",
    "# load and store the data for every symbol\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}_2019.csv'\n",
    "    download_stock_data(symbol, start_date, end_date, output_file)\n",
    "\n",
    "    # read file\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the data with the cleaned rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398e1a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten für Symbol ALV.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2019-01-02  175.500000  175.559998  171.960007  175.000000  1035404\n",
      "2019-01-03  173.320007  175.220001  172.539993  173.160004   883973\n",
      "2019-01-04  174.899994  178.020004  172.960007  177.360001  1234989\n",
      "2019-01-07  178.240005  178.240005  174.600006  175.919998   914854\n",
      "2019-01-08  176.240005  178.179993  175.440002  176.100006   989326\n",
      "...                ...         ...         ...         ...      ...\n",
      "2019-12-19  220.800003  221.000000  218.050003  218.949997  1319860\n",
      "2019-12-20  218.899994  220.850006  218.699997  220.750000  3144001\n",
      "2019-12-23  220.300003  220.850006  219.750000  220.600006   741986\n",
      "2019-12-27  220.800003  221.550003  219.800003  220.600006   583074\n",
      "2019-12-30  220.550003  220.750000  218.399994  218.399994   432548\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol DBK.DE:\n",
      "<bound method NDFrame.head of              Open   High    Low  Close    Volume\n",
      "Date                                            \n",
      "2019-01-02  7.070  7.185  6.836  7.149  16731014\n",
      "2019-01-03  7.069  7.289  7.026  7.098  12433219\n",
      "2019-01-04  7.200  7.450  7.170  7.436  16572099\n",
      "2019-01-07  7.507  7.593  7.405  7.551  12091778\n",
      "2019-01-08  7.596  7.799  7.571  7.623  14390276\n",
      "...           ...    ...    ...    ...       ...\n",
      "2019-12-19  6.999  7.120  6.959  7.120  14098912\n",
      "2019-12-20  7.082  7.138  6.964  7.066  30610130\n",
      "2019-12-23  7.036  7.036  6.906  6.907  10096288\n",
      "2019-12-27  6.892  6.980  6.862  6.906   8065671\n",
      "2019-12-30  6.882  6.955  6.878  6.917   5349478\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol VOW3.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2019-01-02  138.839996  138.839996  134.639999  136.259995  1116700\n",
      "2019-01-03  135.000000  136.639999  134.080002  134.759995   968713\n",
      "2019-01-04  136.039993  140.479996  135.839996  140.479996  1177680\n",
      "2019-01-07  141.899994  142.440002  140.199997  140.639999   936596\n",
      "2019-01-08  139.000000  146.020004  138.360001  143.000000  1517810\n",
      "...                ...         ...         ...         ...      ...\n",
      "2019-12-19  179.199997  179.919998  175.779999  177.100006   928407\n",
      "2019-12-20  176.339996  178.679993  176.240005  176.960007  1664262\n",
      "2019-12-23  176.139999  176.720001  174.820007  176.160004   599601\n",
      "2019-12-27  176.880005  177.119995  175.160004  176.660004   394014\n",
      "2019-12-30  176.500000  176.979996  175.960007  176.240005   276189\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol BMW.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2019-01-02  70.629997  70.660004  68.790001  69.739998  1429230\n",
      "2019-01-03  69.220001  69.809998  69.019997  69.050003  1426463\n",
      "2019-01-04  69.800003  71.769997  69.639999  71.709999  1857639\n",
      "2019-01-07  71.750000  72.320000  71.269997  72.120003  1238553\n",
      "2019-01-08  71.849998  73.680000  71.279999  72.209999  1865750\n",
      "...               ...        ...        ...        ...      ...\n",
      "2019-12-19  75.050003  75.260002  73.540001  74.099998  1770646\n",
      "2019-12-20  74.000000  74.570000  73.879997  74.150002  3441130\n",
      "2019-12-23  73.959999  74.110001  73.160004  73.540001   910739\n",
      "2019-12-27  73.629997  73.989998  73.480003  73.510002   793381\n",
      "2019-12-30  73.209999  73.400002  72.989998  73.139999   467282\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol ADS.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2019-01-02  183.050003  186.899994  181.350006  184.399994   803984\n",
      "2019-01-03  182.699997  186.899994  182.350006  183.949997   776471\n",
      "2019-01-04  186.149994  191.300003  185.449997  191.050003   930881\n",
      "2019-01-07  189.149994  191.300003  189.000000  189.699997   498239\n",
      "2019-01-08  189.699997  197.100006  189.500000  194.300003   834170\n",
      "...                ...         ...         ...         ...      ...\n",
      "2019-12-19  289.700012  290.750000  287.750000  288.350006   630018\n",
      "2019-12-20  288.649994  291.950012  286.399994  291.450012  1393691\n",
      "2019-12-23  292.299988  294.950012  291.000000  291.100006   349958\n",
      "2019-12-27  293.299988  294.200012  290.549988  292.500000   326470\n",
      "2019-12-30  291.299988  292.549988  289.549988  289.799988   215885\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol BEI.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close  Volume\n",
      "Date                                                              \n",
      "2019-01-02   90.940002   92.239998   90.800003   91.860001  271413\n",
      "2019-01-03   91.300003   91.639999   90.360001   91.360001  231211\n",
      "2019-01-04   91.940002   92.320000   91.120003   92.180000  283410\n",
      "2019-01-07   92.260002   92.279999   90.620003   91.279999  269388\n",
      "2019-01-08   90.639999   91.940002   90.379997   90.680000  550498\n",
      "...                ...         ...         ...         ...     ...\n",
      "2019-12-19  103.650002  105.050003  103.449997  105.050003  353249\n",
      "2019-12-20  104.750000  107.050003  104.599998  107.050003  748838\n",
      "2019-12-23  107.250000  107.800003  106.750000  106.849998  247035\n",
      "2019-12-27  107.599998  107.750000  106.599998  106.750000  192494\n",
      "2019-12-30  106.900002  107.000000  105.849998  106.650002  111371\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol DTE.SG:\n",
      "<bound method NDFrame.head of              Open   High    Low  Close  Volume\n",
      "Date                                          \n",
      "2019-01-02  13.69  13.69  13.69  13.69       0\n",
      "2019-01-03  13.69  13.69  13.69  13.69       0\n",
      "2019-01-04  13.69  13.69  13.69  13.69       0\n",
      "2019-01-07  13.69  13.69  13.69  13.69       0\n",
      "2019-01-08  13.69  13.69  13.69  13.69       0\n",
      "...           ...    ...    ...    ...     ...\n",
      "2019-12-19  13.69  13.69  13.69  13.69       0\n",
      "2019-12-20  13.69  13.69  13.69  13.69       0\n",
      "2019-12-23  13.69  13.69  13.69  13.69       0\n",
      "2019-12-27  13.69  13.69  13.69  13.69       0\n",
      "2019-12-30  13.69  13.69  13.69  13.69       0\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol SAP.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2019-01-02   87.000000   87.400002   85.690002   87.010002  2177418\n",
      "2019-01-03   85.500000   85.760002   83.949997   84.309998  3051656\n",
      "2019-01-04   84.750000   86.779999   84.040001   86.440002  3606453\n",
      "2019-01-07   87.199997   87.199997   86.040001   86.620003  2200325\n",
      "2019-01-08   86.750000   88.809998   86.660004   87.970001  2672217\n",
      "...                ...         ...         ...         ...      ...\n",
      "2019-12-19  120.680000  120.680000  118.739998  119.559998  2663483\n",
      "2019-12-20  119.559998  121.459999  119.339996  120.940002  5887926\n",
      "2019-12-23  121.180000  121.360001  119.820000  120.760002  1436685\n",
      "2019-12-27  121.080002  122.040001  120.739998  121.400002  1164464\n",
      "2019-12-30  120.620003  121.099998  120.000000  120.320000   859842\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol 1COV.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2019-01-02  43.150002  43.169998  41.490002  42.900002   922765\n",
      "2019-01-03  42.480000  43.689999  42.000000  42.799999   940568\n",
      "2019-01-04  43.459999  45.439999  43.259998  45.340000  1399264\n",
      "2019-01-07  46.259998  46.270000  44.439999  45.060001   951176\n",
      "2019-01-08  44.990002  46.389999  43.779999  45.840000  1754973\n",
      "...               ...        ...        ...        ...      ...\n",
      "2019-12-19  41.849998  41.910000  41.340000  41.849998  1463673\n",
      "2019-12-20  41.759998  42.200001  41.759998  41.770000  2754367\n",
      "2019-12-23  41.709999  41.990002  41.480000  41.810001   605546\n",
      "2019-12-27  41.880001  42.439999  41.709999  41.820000   535642\n",
      "2019-12-30  41.799999  41.830002  41.330002  41.450001   448776\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol BAS.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2019-01-02  60.500000  60.910000  59.480000  60.720001  2564044\n",
      "2019-01-03  60.099998  60.700001  59.900002  60.020000  2213589\n",
      "2019-01-04  60.779999  63.299999  60.650002  63.189999  4197991\n",
      "2019-01-07  63.900002  63.900002  62.500000  62.900002  2437345\n",
      "2019-01-08  62.919998  64.250000  62.619999  63.220001  3301634\n",
      "...               ...        ...        ...        ...      ...\n",
      "2019-12-19  67.000000  67.290001  66.500000  67.290001  3415313\n",
      "2019-12-20  67.300003  68.180000  67.160004  67.940002  6814933\n",
      "2019-12-23  67.970001  68.150002  67.440002  67.540001  1990353\n",
      "2019-12-27  67.779999  67.989998  67.449997  67.900002  1640149\n",
      "2019-12-30  67.599998  67.809998  67.190002  67.349998   936462\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol EOAN.DE:\n",
      "<bound method NDFrame.head of              Open   High    Low  Close    Volume\n",
      "Date                                            \n",
      "2019-01-02  8.561  8.935  8.542  8.900  11480802\n",
      "2019-01-03  8.846  9.057  8.839  8.998  10113886\n",
      "2019-01-04  9.050  9.132  9.002  9.083   8616427\n",
      "2019-01-07  9.104  9.107  8.941  8.981   8046282\n",
      "2019-01-08  9.009  9.106  8.979  9.027   8197152\n",
      "...           ...    ...    ...    ...       ...\n",
      "2019-12-19  9.601  9.610  9.529  9.571   8864201\n",
      "2019-12-20  9.559  9.603  9.470  9.549  16920221\n",
      "2019-12-23  9.547  9.563  9.458  9.514   6773974\n",
      "2019-12-27  9.562  9.636  9.522  9.556   5283175\n",
      "2019-12-30  9.556  9.566  9.504  9.524   3674747\n",
      "\n",
      "[251 rows x 5 columns]>\n",
      "Daten für Symbol RWE.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2019-01-02  18.885000  19.375000  18.745001  19.299999  4291989\n",
      "2019-01-03  19.180000  19.709999  19.020000  19.525000  3622844\n",
      "2019-01-04  19.690001  20.080000  19.559999  19.924999  3288528\n",
      "2019-01-07  19.990000  20.059999  19.705000  19.900000  3042945\n",
      "2019-01-08  19.900000  20.080000  19.820000  19.980000  2658621\n",
      "...               ...        ...        ...        ...      ...\n",
      "2019-12-19  26.240000  26.680000  26.190001  26.620001  3440329\n",
      "2019-12-20  26.580000  27.250000  26.580000  27.090000  6200575\n",
      "2019-12-23  27.100000  27.150000  26.650000  26.980000  1789385\n",
      "2019-12-27  27.070000  27.340000  27.030001  27.059999  1368804\n",
      "2019-12-30  27.000000  27.350000  26.840000  27.350000  1721932\n",
      "\n",
      "[251 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "# load data for every symbol\n",
    "for symbol in stock_symbols:\n",
    "    # create name for the CSV\n",
    "    csv_file = f'stock_data_{symbol}_2019.csv'\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Set date as index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Select the desired column\n",
    "    selected_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = df[selected_columns]\n",
    "    \n",
    "    # show data\n",
    "    print(f\"Daten für Symbol {symbol}:\")\n",
    "    print(df.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08973d9b",
   "metadata": {},
   "source": [
    "# Compare predictions to actual share values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe67132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich für Symbol ALV.DE:\n",
      "                Actual  Predicted\n",
      "2019-12-30  218.399994  50.421959\n",
      "MSE für Symbol ALV.DE: 28216.620233438978\n",
      "\n",
      "\n",
      "Vergleich für Symbol DBK.DE:\n",
      "            Actual  Predicted\n",
      "2019-12-30   6.917  14.869346\n",
      "MSE für Symbol DBK.DE: 63.23980448753082\n",
      "\n",
      "\n",
      "Vergleich für Symbol VOW3.DE:\n",
      "                Actual  Predicted\n",
      "2019-12-30  176.240005  29.790468\n",
      "MSE für Symbol VOW3.DE: 21447.466968712342\n",
      "\n",
      "\n",
      "Vergleich für Symbol BMW.DE:\n",
      "               Actual  Predicted\n",
      "2019-12-30  73.139999  39.409405\n",
      "MSE für Symbol BMW.DE: 1137.7530144313496\n",
      "\n",
      "\n",
      "Vergleich für Symbol ADS.DE:\n",
      "                Actual  Predicted\n",
      "2019-12-30  289.799988  71.390404\n",
      "MSE für Symbol ADS.DE: 47702.74640288908\n",
      "\n",
      "\n",
      "Vergleich für Symbol BEI.DE:\n",
      "                Actual  Predicted\n",
      "2019-12-30  106.650002    23.6108\n",
      "MSE für Symbol BEI.DE: 6895.509025026873\n",
      "\n",
      "\n",
      "Vergleich für Symbol DTE.SG:\n",
      "            Actual  Predicted\n",
      "2019-12-30   13.69  15.274905\n",
      "MSE für Symbol DTE.SG: 2.5119258382219414\n",
      "\n",
      "\n",
      "Vergleich für Symbol SAP.DE:\n",
      "            Actual  Predicted\n",
      "2019-12-30  120.32  31.452709\n",
      "MSE für Symbol SAP.DE: 7897.395320247291\n",
      "\n",
      "\n",
      "Vergleich für Symbol 1COV.DE:\n",
      "               Actual  Predicted\n",
      "2019-12-30  41.450001  12.450314\n",
      "MSE für Symbol 1COV.DE: 840.9818573976518\n",
      "\n",
      "\n",
      "Vergleich für Symbol BAS.DE:\n",
      "               Actual  Predicted\n",
      "2019-12-30  67.349998  41.113701\n",
      "MSE für Symbol BAS.DE: 688.3433121452108\n",
      "\n",
      "\n",
      "Vergleich für Symbol EOAN.DE:\n",
      "            Actual  Predicted\n",
      "2019-12-30   9.524  11.716145\n",
      "MSE für Symbol EOAN.DE: 4.805497043798823\n",
      "\n",
      "\n",
      "Vergleich für Symbol RWE.DE:\n",
      "            Actual  Predicted\n",
      "2019-12-30   27.35  18.942484\n",
      "MSE für Symbol RWE.DE: 70.6863333529327\n",
      "\n",
      "\n",
      "Gesamter Mean Squared Error für alle Vorhersagen: 9580.671641250938\n",
      "{'ALV.DE': {'prediction_20_days_ahead': 50.42196}, 'DBK.DE': {'prediction_20_days_ahead': 14.869346}, 'VOW3.DE': {'prediction_20_days_ahead': 29.790468}, 'BMW.DE': {'prediction_20_days_ahead': 39.409405}, 'ADS.DE': {'prediction_20_days_ahead': 71.3904}, 'BEI.DE': {'prediction_20_days_ahead': 23.6108}, 'DTE.SG': {'prediction_20_days_ahead': 15.274905}, 'SAP.DE': {'prediction_20_days_ahead': 31.45271}, '1COV.DE': {'prediction_20_days_ahead': 12.450314}, 'BAS.DE': {'prediction_20_days_ahead': 41.1137}, 'EOAN.DE': {'prediction_20_days_ahead': 11.716145}, 'RWE.DE': {'prediction_20_days_ahead': 18.942484}}\n"
     ]
    }
   ],
   "source": [
    "# list to store the mse (mean squared error) for every symbol\n",
    "mse_list = []\n",
    "\n",
    "# list to store the actual and predicted value for every symbol\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "# Comparison of the actual and the predicted value for every symbol\n",
    "for symbol in stock_symbols:\n",
    "    # create name for the CSV\n",
    "    csv_file = f'stock_data_{symbol}_2019.csv'\n",
    "    \n",
    "    # load CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # set date as index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # extract last row\n",
    "    last_row = df.iloc[-1]\n",
    "    \n",
    "    # Extract the value from the \"Close\" column of the last row\n",
    "    actual_close = last_row['Close']\n",
    "    \n",
    "    # Calculate the mean squared error (mse)\n",
    "    mse = mean_squared_error([actual_close], [predictions_dict[symbol]['prediction_20_days_ahead']])\n",
    "    \n",
    "    # Add mse to the list\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    # Create a data frame with just one row for the actual and the predicted \"Close\" value\n",
    "    comparison_df = pd.DataFrame({'Actual': [actual_close], 'Predicted': predictions_dict[symbol]['prediction_20_days_ahead']}, index=[last_row.name])\n",
    "    \n",
    "    # Output of the comparison\n",
    "    print(f\"Vergleich für Symbol {symbol}:\")\n",
    "    print(comparison_df)\n",
    "    print(f\"MSE für Symbol {symbol}: {mse}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Add the actual and predicted value to the main list\n",
    "    all_actual_values.append(actual_close)\n",
    "    all_predicted_values.append(predictions_dict[symbol]['prediction_20_days_ahead'])\n",
    "    \n",
    "# calculate the mean squared error (mse) for all predictions\n",
    "total_mse = mean_squared_error(all_actual_values, all_predicted_values)\n",
    "\n",
    "# Output of the mse for all values\n",
    "print(f\"Gesamter Mean Squared Error für alle Vorhersagen: {total_mse}\")\n",
    "\n",
    "# Define custom encoder class to handle float32 values\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "# Convert NumPy arrays in lists (if present)\n",
    "predictions_dict_serializable = {symbol: predictions.tolist() if isinstance(predictions, np.ndarray) else predictions for symbol, predictions in predictions_dict.items()}\n",
    "print(predictions_dict_serializable)\n",
    "# extract predictions for the mean variance model\n",
    "json_file = 'settings/predictions1Year_dict.json'\n",
    "\n",
    "# Write array in JSON file\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(predictions_dict_serializable, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45dd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
