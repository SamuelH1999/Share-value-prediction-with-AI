{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac4dcf2",
   "metadata": {},
   "source": [
    "# Import librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64238bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "import yfinance as yf\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pickle\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69186c2e",
   "metadata": {},
   "source": [
    "# read predicting sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a46dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(stock_symbols, start_date, end_date, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        # write column headings\n",
    "        f.write('Date,Open,High,Low,Close,Volume\\n')\n",
    "        \n",
    "        #for symbol in stock_symbols:\n",
    "            # load share data for the symbol (Share name) and the given time period\n",
    "        stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "        stock_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]  # Auswahl der gewünschten Spalten\n",
    "        stock_data.to_csv(f, header=False)  # Schreiben der Daten in die Datei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50633fe",
   "metadata": {},
   "source": [
    "# load time sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074f3def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Enter symbols\n",
    "stock_symbols = ['ALV.DE', 'DBK.DE', 'VOW3.DE', 'BMW.DE', 'ADS.DE', 'BEI.DE', 'DTE.SG', 'SAP.DE', '1COV.DE', 'BAS.DE', 'EOAN.DE', 'RWE.DE']\n",
    "start_date = '2018-10-01'\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "# load and store the data for every share\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}.csv'\n",
    "    download_stock_data(symbol, start_date, end_date, output_file)\n",
    "\n",
    "    # read CSV and select select the desired columns\n",
    "    df = pd.read_csv(output_file, usecols=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    \n",
    "    # Search CSV file for empty lines and remove them\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # filter the empty lines\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the file with the adjusted rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e1a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data frames for different symbols in the dictionary\n",
    "dfPre = {}\n",
    "\n",
    "for symbol in stock_symbols:\n",
    "    # load CSV\n",
    "    dfPre[symbol] = pd.read_csv(f'stock_data_{symbol}.csv')\n",
    "\n",
    "    # Drop empty rows\n",
    "    dfPre[symbol].dropna(inplace=True)\n",
    "\n",
    "    # transform date to index\n",
    "    dfPre[symbol].set_index('Date', inplace=True)\n",
    "\n",
    "    # Check the number of rows\n",
    "    num_rows = dfPre[symbol].shape[0]\n",
    "\n",
    "    # If more than 60 rows, keep the last 60 rows\n",
    "    if num_rows > 60:\n",
    "        dfPre[symbol] = dfPre[symbol].tail(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63ed050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor der Behandlung für ALV.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für ALV.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für DBK.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für DBK.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für VOW3.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für VOW3.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für BMW.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für BMW.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für ADS.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für ADS.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für BEI.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für BEI.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für DTE.SG gefunden: False\n",
      "Fehlende Werte nach der Behandlung für DTE.SG gefunden: False\n",
      "Fehlende Werte vor der Behandlung für SAP.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für SAP.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für 1COV.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für 1COV.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für BAS.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für BAS.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für EOAN.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für EOAN.DE gefunden: False\n",
      "Fehlende Werte vor der Behandlung für RWE.DE gefunden: False\n",
      "Fehlende Werte nach der Behandlung für RWE.DE gefunden: False\n",
      "Länge des Datensatzes für ALV.DE: 60\n",
      "Länge des Datensatzes für DBK.DE: 60\n",
      "Länge des Datensatzes für VOW3.DE: 60\n",
      "Länge des Datensatzes für BMW.DE: 60\n",
      "Länge des Datensatzes für ADS.DE: 60\n",
      "Länge des Datensatzes für BEI.DE: 60\n",
      "Länge des Datensatzes für DTE.SG: 60\n",
      "Länge des Datensatzes für SAP.DE: 60\n",
      "Länge des Datensatzes für 1COV.DE: 60\n",
      "Länge des Datensatzes für BAS.DE: 60\n",
      "Länge des Datensatzes für EOAN.DE: 60\n",
      "Länge des Datensatzes für RWE.DE: 60\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_values_beforePre = {symbol: dfPre[symbol].isnull().values.any() for symbol in stock_symbols}\n",
    "\n",
    "# missing values are replaced with teh mean of the row before and after the actual row\n",
    "for symbol in stock_symbols:\n",
    "    for column in dfPre[symbol].columns:\n",
    "        missing_valuesPre = dfPre[symbol][column].isnull()\n",
    "        dfPre[symbol].loc[missing_valuesPre, column] = (dfPre[symbol][column].shift() + dfPre[symbol][column].shift(-1)) / 2\n",
    "\n",
    "# Check if there are still any missing values \n",
    "missing_values_afterPre = {symbol: dfPre[symbol].isnull().values.any() for symbol in stock_symbols}\n",
    "\n",
    "# Output of the missing values before and after the Treatment\n",
    "for symbol in stock_symbols:\n",
    "    print(f\"Fehlende Werte vor der Behandlung für {symbol} gefunden:\", missing_values_beforePre[symbol])\n",
    "    print(f\"Fehlende Werte nach der Behandlung für {symbol} gefunden:\", missing_values_afterPre[symbol])\n",
    "\n",
    "# Output of the length of the data frame for all symbols\n",
    "for symbol in stock_symbols:\n",
    "    print(f\"Länge des Datensatzes für {symbol}:\", len(dfPre[symbol]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6894f0f",
   "metadata": {},
   "source": [
    "# Data normalization prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda529dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scaler\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "    \n",
    "# min-max scale factors\n",
    "min_value = scaler.data_min_\n",
    "max_value = scaler.data_max_\n",
    "# normalize the data for all symbols\n",
    "nfPre = {}\n",
    "nfPre_normalized = {}\n",
    "for symbol in stock_symbols:\n",
    "    # Copy the data fram and remove the column \"Date\" for every symbol\n",
    "    nfPre[symbol] = dfPre[symbol].copy()\n",
    "    \n",
    "    # Remove the index name \n",
    "    nfPre[symbol].index.name = None\n",
    "\n",
    "    # normalize the data for every symbol, except for the date (Index)\n",
    "    nfPre_normalized[symbol] = scaler.transform(nfPre[symbol])\n",
    "\n",
    "    # Create a new data frame with the normalized data and the original index for every symbol\n",
    "    nfPre[symbol] = pd.DataFrame(nfPre_normalized[symbol], columns=nfPre[symbol].columns, index=nfPre[symbol].index)\n",
    "\n",
    "    # Convert DataFrame to NumPy array for every symbol\n",
    "    nfPre[symbol] = nfPre[symbol].to_numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92ed14",
   "metadata": {},
   "source": [
    "# Daten preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a8ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store X_pre for every symbol in the dictionary\n",
    "X_pre_dict = {}\n",
    "\n",
    "# Iterate over each symbol\n",
    "for symbol in stock_symbols:\n",
    "    \n",
    "    nfPre_symbol = nfPre[symbol]\n",
    "    \n",
    "    # Define size for the current symbol\n",
    "    nfPre_size_symbol = len(nfPre_symbol)\n",
    "    \n",
    "    # Add external dimension\n",
    "    X_pre_symbol = np.expand_dims(nfPre_symbol[:nfPre_size_symbol], axis=0)\n",
    "    \n",
    "    # Transform to Tensor\n",
    "    X_pre_symbol_tensor = tf.convert_to_tensor(X_pre_symbol, dtype=tf.float32)\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    X_pre_dict[symbol] = X_pre_symbol_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4c911",
   "metadata": {},
   "source": [
    "# Model importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c34d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = {}\n",
    "\n",
    "for symbol in stock_symbols:\n",
    "    # Load the stored model\n",
    "    loaded_models[symbol] = load_model(f'Predict1Year_{symbol}.h5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa84085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALV.DE': <Sequential name=sequential, built=True>, 'DBK.DE': <Sequential name=sequential, built=True>, 'VOW3.DE': <Sequential name=sequential, built=True>, 'BMW.DE': <Sequential name=sequential, built=True>, 'ADS.DE': <Sequential name=sequential, built=True>, 'BEI.DE': <Sequential name=sequential, built=True>, 'DTE.SG': <Sequential name=sequential, built=True>, 'SAP.DE': <Sequential name=sequential, built=True>, '1COV.DE': <Sequential name=sequential, built=True>, 'BAS.DE': <Sequential name=sequential, built=True>, 'EOAN.DE': <Sequential name=sequential, built=True>, 'RWE.DE': <Sequential name=sequential, built=True>}\n"
     ]
    }
   ],
   "source": [
    "print(loaded_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90458c92",
   "metadata": {},
   "source": [
    "# Prediction for the unkonown sequence and transform back into monetary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32404dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(symbol):\n",
    "    # Predict the current share(symbol)\n",
    "    predictions = loaded_models[symbol].predict(X_pre_dict[symbol])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0c7e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "Zurücktransformierte Vorhersagen für ALV.DE:\n",
      "[[1.5086728e+02 1.4913466e+02 1.5042892e+02 1.4720120e+02 8.2779038e+05]]\n",
      "147.2012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "Zurücktransformierte Vorhersagen für DBK.DE:\n",
      "[[-3.2812428e+01 -4.7802361e+01 -1.1728985e+01 -1.5804074e+01\n",
      "   2.0142701e+06]]\n",
      "-15.804074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "Zurücktransformierte Vorhersagen für VOW3.DE:\n",
      "[[1.3322235e+02 1.3549811e+02 1.3520354e+02 1.3469041e+02 7.8726838e+05]]\n",
      "134.69041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "Zurücktransformierte Vorhersagen für BMW.DE:\n",
      "[[8.4228035e+01 8.5057350e+01 8.3970306e+01 8.4534317e+01 1.2611940e+06]]\n",
      "84.53432\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F8E46D1120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "Zurücktransformierte Vorhersagen für ADS.DE:\n",
      "[[ 2.3350224e+02  2.3954001e+02  2.2566693e+02  2.1879506e+02\n",
      "  -3.5944155e+06]]\n",
      "218.79506\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F8E46D1D80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "Zurücktransformierte Vorhersagen für BEI.DE:\n",
      "[[9.7006630e+01 9.8084259e+01 9.6621674e+01 9.7625023e+01 7.2316925e+05]]\n",
      "97.62502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "Zurücktransformierte Vorhersagen für DTE.SG:\n",
      "[[ 1.7933591e+02  2.1543494e+02  5.0951042e+01  1.8984802e+02\n",
      "  -8.5270056e+05]]\n",
      "189.84802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Zurücktransformierte Vorhersagen für SAP.DE:\n",
      "[[9.3881180e+01 9.3950302e+01 9.1989708e+01 9.2648705e+01 1.7923632e+06]]\n",
      "92.648705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "Zurücktransformierte Vorhersagen für 1COV.DE:\n",
      "[[1.5262473e+02 1.4892023e+02 1.5259058e+02 1.5010686e+02 9.8023862e+05]]\n",
      "150.10686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "Zurücktransformierte Vorhersagen für BAS.DE:\n",
      "[[1.06455284e+02 1.06752708e+02 1.05087021e+02 1.06495789e+02\n",
      "  1.35214525e+06]]\n",
      "106.49579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "Zurücktransformierte Vorhersagen für EOAN.DE:\n",
      "[[5.1914238e+01 5.0420433e+01 6.8491570e+01 5.4418011e+01 1.1163362e+06]]\n",
      "54.41801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "Zurücktransformierte Vorhersagen für RWE.DE:\n",
      "[[1.01503586e+02 9.42561951e+01 9.27877655e+01 9.70643997e+01\n",
      "  7.29172188e+05]]\n",
      "97.0644\n",
      "{'ALV.DE': {'prediction_20_days_ahead': 147.2012}, 'DBK.DE': {'prediction_20_days_ahead': -15.804074}, 'VOW3.DE': {'prediction_20_days_ahead': 134.69041}, 'BMW.DE': {'prediction_20_days_ahead': 84.53432}, 'ADS.DE': {'prediction_20_days_ahead': 218.79506}, 'BEI.DE': {'prediction_20_days_ahead': 97.62502}, 'DTE.SG': {'prediction_20_days_ahead': 189.84802}, 'SAP.DE': {'prediction_20_days_ahead': 92.648705}, '1COV.DE': {'prediction_20_days_ahead': 150.10686}, 'BAS.DE': {'prediction_20_days_ahead': 106.49579}, 'EOAN.DE': {'prediction_20_days_ahead': 54.41801}, 'RWE.DE': {'prediction_20_days_ahead': 97.0644}}\n"
     ]
    }
   ],
   "source": [
    "# create dictionary to store the prediction for every symbol\n",
    "predictions_dict = {}\n",
    "predictions = {}\n",
    "\n",
    "# Iterate over every symbol\n",
    "for symbol in stock_symbols:\n",
    "\n",
    "    # Prediction for the actual symbol\n",
    "    predictions[symbol] = prediction(symbol)\n",
    "\n",
    "    # Inverse transformation of the prediction\n",
    "    predictions_original_scale_symbol = scaler.inverse_transform(predictions[symbol])\n",
    "\n",
    "    # extract the prediction 20 days in the future\n",
    "    prediction_20_days_ahead_symbol = predictions_original_scale_symbol[0][-2]\n",
    "\n",
    "    # store the prediction for the current symbol\n",
    "    predictions_dict[symbol] = {\n",
    "        'prediction_20_days_ahead': prediction_20_days_ahead_symbol\n",
    "    }\n",
    "\n",
    "    # Output the values of the inverse transformation\n",
    "    print(f\"Zurücktransformierte Vorhersagen für {symbol}:\")\n",
    "    print(predictions_original_scale_symbol)\n",
    "    print(prediction_20_days_ahead_symbol)\n",
    "print(predictions_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a4f65",
   "metadata": {},
   "source": [
    "# read test CSV from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fed4224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01\n",
      "2018-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# time period\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2019-12-31'\n",
    "print(start_date)\n",
    "print(end_date)\n",
    "\n",
    "# load and store the data for every symbol\n",
    "for symbol in stock_symbols:\n",
    "    output_file = f'stock_data_{symbol}_2019.csv'\n",
    "    download_stock_data(symbol, start_date, end_date, output_file)\n",
    "\n",
    "    # read file\n",
    "    with open(output_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # filter the empty rows\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Overwrite the data with the cleaned rows\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398e1a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten für Symbol ALV.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2018-01-02  193.100006  193.360001  190.500000  192.699997  1479063\n",
      "2018-01-03  193.960007  194.000000  191.580002  193.000000  1378661\n",
      "2018-01-04  194.279999  196.720001  194.179993  195.500000  1551761\n",
      "2018-01-05  196.199997  198.559998  195.839996  198.559998  1319824\n",
      "2018-01-08  199.660004  200.000000  198.520004  198.860001   975348\n",
      "...                ...         ...         ...         ...      ...\n",
      "2018-12-19  175.600006  177.199997  174.679993  175.940002  1326802\n",
      "2018-12-20  173.199997  175.820007  172.860001  174.960007  1599316\n",
      "2018-12-21  174.600006  175.220001  173.699997  175.020004  3334380\n",
      "2018-12-27  174.679993  174.779999  170.460007  172.160004  1214929\n",
      "2018-12-28  172.800003  175.919998  172.479996  175.139999   792046\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol DBK.DE:\n",
      "<bound method NDFrame.head of               Open       High     Low      Close    Volume\n",
      "Date                                                      \n",
      "2018-01-02  16.034  16.087999  15.780  15.958000  12548973\n",
      "2018-01-03  16.070  16.077999  15.812  15.910000  15445581\n",
      "2018-01-04  15.970  16.358000  15.884  16.332001  17568313\n",
      "2018-01-05  16.400  16.455999  15.432  15.490000  33995534\n",
      "2018-01-08  15.500  15.520000  15.106  15.340000  22861725\n",
      "...            ...        ...     ...        ...       ...\n",
      "2018-12-19   7.701   7.785000   7.515   7.530000  11792807\n",
      "2018-12-20   7.400   7.400000   6.994   7.000000  28220174\n",
      "2018-12-21   7.000   7.100000   6.842   7.042000  38586144\n",
      "2018-12-27   7.100   7.130000   6.678   6.750000  17761385\n",
      "2018-12-28   6.810   7.009000   6.781   6.967000   9429341\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol VOW3.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2018-01-02  166.800003  167.119995  161.479996  165.699997  1319104\n",
      "2018-01-03  166.500000  171.940002  166.179993  171.440002  1426451\n",
      "2018-01-04  172.500000  174.839996  171.279999  174.440002  1564533\n",
      "2018-01-05  176.500000  179.679993  176.300003  179.199997  2195933\n",
      "2018-01-08  180.899994  180.979996  179.139999  179.839996  1162286\n",
      "...                ...         ...         ...         ...      ...\n",
      "2018-12-19  146.679993  148.839996  146.419998  146.880005   986274\n",
      "2018-12-20  145.000000  145.639999  143.100006  143.899994  1328154\n",
      "2018-12-21  142.479996  146.740005  141.119995  143.300003  2650052\n",
      "2018-12-27  143.380005  143.500000  136.279999  137.440002  1608052\n",
      "2018-12-28  138.399994  140.080002  138.000000  138.919998   614699\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol BMW.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2018-01-02  86.769997  86.820000  83.879997  86.400002  2673332\n",
      "2018-01-03  87.000000  87.360001  86.459999  86.860001  1396762\n",
      "2018-01-04  87.800003  88.339996  87.379997  87.480003  1872794\n",
      "2018-01-05  87.000000  88.739998  87.000000  88.500000  1911027\n",
      "2018-01-08  89.150002  90.309998  89.110001  89.669998  2298840\n",
      "...               ...        ...        ...        ...      ...\n",
      "2018-12-19  73.739998  74.300003  73.410004  73.449997  1582367\n",
      "2018-12-20  72.739998  72.900002  71.650002  71.839996  2950979\n",
      "2018-12-21  71.419998  72.040001  70.230003  71.930000  4978117\n",
      "2018-12-27  71.779999  72.160004  69.120003  69.860001  1828170\n",
      "2018-12-28  70.349998  70.760002  70.209999  70.699997  1031948\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol ADS.DE:\n",
      "<bound method NDFrame.head of                   Open        High         Low       Close   Volume\n",
      "Date                                                               \n",
      "2018-01-02  167.149994  167.699997  165.250000  167.149994   587067\n",
      "2018-01-03  167.600006  168.050003  166.050003  168.050003   662050\n",
      "2018-01-04  169.149994  171.699997  168.500000  170.250000   806719\n",
      "2018-01-05  171.699997  172.649994  171.000000  172.050003   693116\n",
      "2018-01-08  174.100006  174.149994  172.399994  172.750000   805948\n",
      "...                ...         ...         ...         ...      ...\n",
      "2018-12-19  186.949997  189.050003  186.300003  187.050003   697398\n",
      "2018-12-20  184.000000  185.300003  182.750000  183.750000   820234\n",
      "2018-12-21  183.000000  185.550003  179.149994  184.750000  2238677\n",
      "2018-12-27  185.149994  185.250000  178.149994  180.100006   807876\n",
      "2018-12-28  181.149994  183.649994  181.100006  182.399994   443391\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol BEI.DE:\n",
      "<bound method NDFrame.head of                   Open        High        Low       Close  Volume\n",
      "Date                                                             \n",
      "2018-01-02   97.699997   97.699997  95.760002   96.199997  385905\n",
      "2018-01-03   96.180000   97.099998  96.099998   96.680000  274044\n",
      "2018-01-04   97.160004   98.160004  96.800003   98.059998  457445\n",
      "2018-01-05   98.239998   99.480003  98.019997   99.279999  332758\n",
      "2018-01-08  100.000000  100.699997  98.199997  100.300003  813959\n",
      "...                ...         ...        ...         ...     ...\n",
      "2018-12-19   92.279999   93.059998  91.980003   93.059998  438777\n",
      "2018-12-20   92.480003   93.180000  92.040001   92.760002  365041\n",
      "2018-12-21   92.879997   92.940002  91.300003   92.739998  786151\n",
      "2018-12-27   92.379997   92.879997  89.839996   90.559998  400756\n",
      "2018-12-28   91.080002   91.519997  90.639999   91.160004  171410\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol DTE.SG:\n",
      "<bound method NDFrame.head of               Open    High     Low   Close  Volume\n",
      "Date                                              \n",
      "2018-01-02  14.875  14.882  14.700  14.872  119467\n",
      "2018-01-03  14.880  14.885  14.700  14.835  108653\n",
      "2018-01-04  14.890  14.930  14.745  14.890  149960\n",
      "2018-01-05  14.930  14.985  14.835  14.940  153890\n",
      "2018-01-08  15.010  15.090  14.970  15.040  119210\n",
      "...            ...     ...     ...     ...     ...\n",
      "2018-12-19  13.690  13.690  13.690  13.690       0\n",
      "2018-12-20  13.690  13.690  13.690  13.690       0\n",
      "2018-12-21  13.690  13.690  13.690  13.690       0\n",
      "2018-12-27  13.690  13.690  13.690  13.690       0\n",
      "2018-12-28  13.690  13.690  13.690  13.690       0\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol SAP.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2018-01-02  93.349998  93.949997  92.120003  92.800003  2334984\n",
      "2018-01-03  93.000000  94.650002  92.629997  94.070000  2346852\n",
      "2018-01-04  94.620003  95.430000  94.339996  95.089996  2403598\n",
      "2018-01-05  95.209999  96.440002  95.209999  96.440002  2114301\n",
      "2018-01-08  96.879997  96.970001  95.809998  96.269997  1790705\n",
      "...               ...        ...        ...        ...      ...\n",
      "2018-12-19  87.900002  89.570000  87.709999  89.220001  2824088\n",
      "2018-12-20  87.779999  88.940002  87.430000  87.769997  3259932\n",
      "2018-12-21  87.500000  87.980003  85.699997  86.419998  6980413\n",
      "2018-12-27  86.800003  87.139999  84.680000  85.790001  3073209\n",
      "2018-12-28  86.330002  87.529999  86.000000  86.930000  1758428\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol 1COV.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2018-01-02  86.139999  86.379997  84.620003  85.639999   438798\n",
      "2018-01-03  85.739998  87.180000  85.440002  86.760002   532976\n",
      "2018-01-04  87.400002  88.839996  87.339996  88.419998   738912\n",
      "2018-01-05  88.400002  89.000000  87.279999  88.300003   723803\n",
      "2018-01-08  88.300003  88.879997  87.120003  87.199997   823032\n",
      "...               ...        ...        ...        ...      ...\n",
      "2018-12-19  43.570000  43.630001  42.790001  43.150002  1631332\n",
      "2018-12-20  42.500000  42.709999  41.419998  41.900002  1576720\n",
      "2018-12-21  41.509998  43.330002  41.509998  43.279999  2499814\n",
      "2018-12-27  43.599998  44.169998  41.570000  42.130001   933259\n",
      "2018-12-28  42.599998  43.880001  42.240002  43.180000   648123\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol BAS.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2018-01-02  91.559998  91.639999  90.570000  91.309998  2418347\n",
      "2018-01-03  91.410004  92.230003  91.320000  91.580002  2014077\n",
      "2018-01-04  92.220001  93.809998  92.089996  93.550003  2424483\n",
      "2018-01-05  93.410004  94.849998  93.370003  94.849998  2147921\n",
      "2018-01-08  94.639999  95.180000  94.379997  95.010002  1743044\n",
      "...               ...        ...        ...        ...      ...\n",
      "2018-12-19  59.689999  60.770000  59.480000  60.340000  4504619\n",
      "2018-12-20  59.480000  60.049999  59.150002  59.750000  3855756\n",
      "2018-12-21  59.580002  60.950001  59.529999  60.720001  8841494\n",
      "2018-12-27  60.599998  61.049999  59.009998  59.669998  3574121\n",
      "2018-12-28  60.189999  60.889999  60.000000  60.400002  1772062\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol EOAN.DE:\n",
      "<bound method NDFrame.head of              Open   High    Low  Close    Volume\n",
      "Date                                            \n",
      "2018-01-02  9.090  9.113  8.998  9.078  10660669\n",
      "2018-01-03  9.078  9.133  8.981  9.086   9891646\n",
      "2018-01-04  9.120  9.158  9.032  9.109  15445164\n",
      "2018-01-05  9.130  9.248  9.094  9.237  11986371\n",
      "2018-01-08  9.306  9.316  9.186  9.208  10324348\n",
      "...           ...    ...    ...    ...       ...\n",
      "2018-12-19  8.897  8.999  8.883  8.965  10697273\n",
      "2018-12-20  8.889  8.944  8.813  8.895  12874187\n",
      "2018-12-21  8.915  8.939  8.783  8.864  18955695\n",
      "2018-12-27  8.829  8.830  8.419  8.524  14212275\n",
      "2018-12-28  8.550  8.643  8.498  8.627   5684732\n",
      "\n",
      "[252 rows x 5 columns]>\n",
      "Daten für Symbol RWE.DE:\n",
      "<bound method NDFrame.head of                  Open       High        Low      Close   Volume\n",
      "Date                                                           \n",
      "2018-01-02  17.100000  17.389999  16.875000  17.299999  4500143\n",
      "2018-01-03  17.350000  17.540001  17.219999  17.459999  3654456\n",
      "2018-01-04  17.545000  17.600000  17.305000  17.465000  3830500\n",
      "2018-01-05  17.459999  17.680000  17.360001  17.639999  4423702\n",
      "2018-01-08  17.805000  17.950001  17.639999  17.780001  4682072\n",
      "...               ...        ...        ...        ...      ...\n",
      "2018-12-19  19.105000  19.389999  18.975000  19.320000  2897544\n",
      "2018-12-20  19.155001  19.315001  18.915001  19.155001  4527511\n",
      "2018-12-21  19.100000  19.180000  18.905001  19.094999  5444153\n",
      "2018-12-27  18.965000  19.000000  18.090000  18.490000  5175236\n",
      "2018-12-28  18.500000  19.070000  18.360001  18.965000  2925476\n",
      "\n",
      "[252 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "# load data for every symbol\n",
    "for symbol in stock_symbols:\n",
    "    # create name for the CSV\n",
    "    csv_file = f'stock_data_{symbol}_2019.csv'\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Set date as index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Select the desired column\n",
    "    selected_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = df[selected_columns]\n",
    "    \n",
    "    # show data\n",
    "    print(f\"Daten für Symbol {symbol}:\")\n",
    "    print(df.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08973d9b",
   "metadata": {},
   "source": [
    "# Compare predictions to actual share values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe67132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich für Symbol ALV.DE:\n",
      "                Actual   Predicted\n",
      "2018-12-28  175.139999  147.201202\n",
      "MSE für Symbol ALV.DE: 780.5763776435051\n",
      "\n",
      "\n",
      "Vergleich für Symbol DBK.DE:\n",
      "            Actual  Predicted\n",
      "2018-12-28   6.967 -15.804074\n",
      "MSE für Symbol DBK.DE: 518.5218245504111\n",
      "\n",
      "\n",
      "Vergleich für Symbol VOW3.DE:\n",
      "                Actual   Predicted\n",
      "2018-12-28  138.919998  134.690414\n",
      "MSE für Symbol VOW3.DE: 17.889378615655005\n",
      "\n",
      "\n",
      "Vergleich für Symbol BMW.DE:\n",
      "               Actual  Predicted\n",
      "2018-12-28  70.699997  84.534317\n",
      "MSE für Symbol BMW.DE: 191.38841175381094\n",
      "\n",
      "\n",
      "Vergleich für Symbol ADS.DE:\n",
      "                Actual   Predicted\n",
      "2018-12-28  182.399994  218.795059\n",
      "MSE für Symbol ADS.DE: 1324.6007787457181\n",
      "\n",
      "\n",
      "Vergleich für Symbol BEI.DE:\n",
      "               Actual  Predicted\n",
      "2018-12-28  91.160004  97.625023\n",
      "MSE für Symbol BEI.DE: 41.79647359350929\n",
      "\n",
      "\n",
      "Vergleich für Symbol DTE.SG:\n",
      "            Actual   Predicted\n",
      "2018-12-28   13.69  189.848022\n",
      "MSE für Symbol DTE.SG: 31031.649025185856\n",
      "\n",
      "\n",
      "Vergleich für Symbol SAP.DE:\n",
      "            Actual  Predicted\n",
      "2018-12-28   86.93  92.648705\n",
      "MSE für Symbol SAP.DE: 32.70357799739577\n",
      "\n",
      "\n",
      "Vergleich für Symbol 1COV.DE:\n",
      "            Actual   Predicted\n",
      "2018-12-28   43.18  150.106857\n",
      "MSE für Symbol 1COV.DE: 11433.35274674982\n",
      "\n",
      "\n",
      "Vergleich für Symbol BAS.DE:\n",
      "               Actual   Predicted\n",
      "2018-12-28  60.400002  106.495789\n",
      "MSE für Symbol BAS.DE: 2124.8215836058953\n",
      "\n",
      "\n",
      "Vergleich für Symbol EOAN.DE:\n",
      "            Actual  Predicted\n",
      "2018-12-28   8.627  54.418011\n",
      "MSE für Symbol EOAN.DE: 2096.8166752718616\n",
      "\n",
      "\n",
      "Vergleich für Symbol RWE.DE:\n",
      "            Actual  Predicted\n",
      "2018-12-28  18.965    97.0644\n",
      "MSE für Symbol RWE.DE: 6099.516212671311\n",
      "\n",
      "\n",
      "Gesamter Mean Squared Error für alle Vorhersagen: 4641.136088865395\n",
      "Gesamte Standardabweichung für alle Vorhersagen: 68.12588413272444\n",
      "Gesamte Standardabweichung pro Aktie: 5.67715701106037\n",
      "{'ALV.DE': {'prediction_20_days_ahead': 147.2012}, 'DBK.DE': {'prediction_20_days_ahead': -15.804074}, 'VOW3.DE': {'prediction_20_days_ahead': 134.69041}, 'BMW.DE': {'prediction_20_days_ahead': 84.53432}, 'ADS.DE': {'prediction_20_days_ahead': 218.79506}, 'BEI.DE': {'prediction_20_days_ahead': 97.62502}, 'DTE.SG': {'prediction_20_days_ahead': 189.84802}, 'SAP.DE': {'prediction_20_days_ahead': 92.648705}, '1COV.DE': {'prediction_20_days_ahead': 150.10686}, 'BAS.DE': {'prediction_20_days_ahead': 106.49579}, 'EOAN.DE': {'prediction_20_days_ahead': 54.41801}, 'RWE.DE': {'prediction_20_days_ahead': 97.0644}}\n"
     ]
    }
   ],
   "source": [
    "# list to store the mse (mean squared error) for every symbol\n",
    "mse_list = []\n",
    "\n",
    "# list to store the actual and predicted value for every symbol\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "# Comparison of the actual and the predicted value for every symbol\n",
    "for symbol in stock_symbols:\n",
    "    # create name for the CSV\n",
    "    csv_file = f'stock_data_{symbol}_2019.csv'\n",
    "    \n",
    "    # load CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # set date as index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # extract last row\n",
    "    last_row = df.iloc[-1]\n",
    "    \n",
    "    # Extract the value from the \"Close\" column of the last row\n",
    "    actual_close = last_row['Close']\n",
    "    \n",
    "    # Calculate the mean squared error (mse)\n",
    "    mse = mean_squared_error([actual_close], [predictions_dict[symbol]['prediction_20_days_ahead']])\n",
    "    \n",
    "    # Add mse to the list\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    # Create a data frame with just one row for the actual and the predicted \"Close\" value\n",
    "    comparison_df = pd.DataFrame({'Actual': [actual_close], 'Predicted': predictions_dict[symbol]['prediction_20_days_ahead']}, index=[last_row.name])\n",
    "    \n",
    "    # Output of the comparison\n",
    "    print(f\"Vergleich für Symbol {symbol}:\")\n",
    "    print(comparison_df)\n",
    "    print(f\"MSE für Symbol {symbol}: {mse}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Add the actual and predicted value to the main list\n",
    "    all_actual_values.append(actual_close)\n",
    "    all_predicted_values.append(predictions_dict[symbol]['prediction_20_days_ahead'])\n",
    "    \n",
    "# calculate the mean squared error (mse) for all predictions\n",
    "total_mse = mean_squared_error(all_actual_values, all_predicted_values)\n",
    "standard_deviation = math.sqrt(total_mse)\n",
    "standard_deviation_share = standard_deviation / 12\n",
    "\n",
    "# Output of the mse for all values\n",
    "print(f\"Gesamter Mean Squared Error für alle Vorhersagen: {total_mse}\")\n",
    "print(f\"Gesamte Standardabweichung für alle Vorhersagen: {standard_deviation}\")\n",
    "print(f\"Gesamte Standardabweichung pro Aktie: {standard_deviation_share}\")\n",
    "\n",
    "# Define custom encoder class to handle float32 values\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "# Convert NumPy arrays in lists (if present)\n",
    "predictions_dict_serializable = {symbol: predictions.tolist() if isinstance(predictions, np.ndarray) else predictions for symbol, predictions in predictions_dict.items()}\n",
    "print(predictions_dict_serializable)\n",
    "# extract predictions for the mean variance model\n",
    "json_file = 'settings/predictions1Year_dict.json'\n",
    "\n",
    "# Write array in JSON file\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(predictions_dict_serializable, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45dd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
